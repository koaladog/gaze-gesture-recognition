{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 28212,
     "status": "ok",
     "timestamp": 1636368195657,
     "user": {
      "displayName": "Yuki Tabuchi",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08215908307688629308"
     },
     "user_tz": -540
    },
    "id": "8qybrePxr4zz"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as utils\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "# from scipy.spatial import distance\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from fastdtw import fastdtw\n",
    "from tslearn.neighbors import KNeighborsTimeSeriesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import copy\n",
    "# import datetime\n",
    "import itertools\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from natsort import natsorted\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 353,
     "status": "ok",
     "timestamp": 1636368197247,
     "user": {
      "displayName": "Yuki Tabuchi",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08215908307688629308"
     },
     "user_tz": -540
    },
    "id": "0HxsKGZ-r4z3"
   },
   "outputs": [],
   "source": [
    "SENSORS_NUM = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7-qFPPJMr4z5"
   },
   "source": [
    "# 1 関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1636368197249,
     "user": {
      "displayName": "Yuki Tabuchi",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08215908307688629308"
     },
     "user_tz": -540
    },
    "id": "nRdrUHrWr4z4"
   },
   "outputs": [],
   "source": [
    "def fix_seed(seed):\n",
    "    # random\n",
    "    random.seed(seed)\n",
    "    # Numpy\n",
    "    np.random.seed(seed)\n",
    "    # Pytorch\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    # Tensorflow\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "#     torch.backends.cudnn.benchmark = True\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "    torch.use_deterministic_algorithms = True\n",
    "\n",
    "# SEED = 0\n",
    "# fix_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 ファインチューニング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_cnn_finetuning(train_list_df, test_list_df, DIR_OUT, count, pre_best_eval_acc, conv_size, model_path, num_epochs):\n",
    "\n",
    "    over_sensors_num = 4\n",
    "    image_size_height = 16+over_sensors_num\n",
    "    image_size_width = len([col for col in test_list_df[0].columns if str(col).isdecimal()])\n",
    "\n",
    "    # 画像に直す\n",
    "    # dataframeに直してるので時間かかる\n",
    "    def sensor_to_image(list_df):\n",
    "        data_list_df = []\n",
    "        label_list = []\n",
    "        for i in tqdm(range(len(list_df[0]))):\n",
    "            temp_list_df = []\n",
    "            label_list.append(list_df[0].iloc[i]['Label'])\n",
    "\n",
    "            for df in list_df:\n",
    "                temp_list_df.append(pd.DataFrame(df.iloc[i]).T.drop(['Label', 'Trial', 'Label_Trial'], axis=1))\n",
    "\n",
    "            data_list_df.append(pd.concat(temp_list_df, sort=False))\n",
    "            \n",
    "        # センサ順を一周するよう入れ替え、over_sensors_num分上のセンサを下に延長\n",
    "        for i in range(len(list_df[0])):\n",
    "            data_list_df[i] = data_list_df[i].reset_index(drop=True).reindex(index=[0, 1, 2,3,4,5,6,15,14,13,12,11,10,9,8,7]).reset_index(drop=True)\n",
    "            data_list_df[i] = pd.concat([data_list_df[i], data_list_df[i].iloc[:over_sensors_num]]).reset_index(drop=True)\n",
    " \n",
    "        return data_list_df, label_list\n",
    "\n",
    "    train_image_list, train_label_list = sensor_to_image(train_list_df)\n",
    "    test_image_list, test_label_list = sensor_to_image(test_list_df)\n",
    "\n",
    "\n",
    "    def df_to_nd(image_list):\n",
    "        for i in range(len(image_list)):\n",
    "            image_list[i] = image_list[i].values\n",
    "\n",
    "        image_list = np.array(image_list)\n",
    "\n",
    "        return image_list\n",
    "    \n",
    "    train_image_list = df_to_nd(train_image_list)\n",
    "    train_image_list = np.reshape(train_image_list, (len(train_list_df[0]), 1, image_size_height, image_size_width), order='F')\n",
    "\n",
    "    test_image_list = df_to_nd(test_image_list)\n",
    "    test_image_list = np.reshape(test_image_list, (len(test_list_df[0]), 1, image_size_height, image_size_width), order='F')\n",
    "\n",
    "\n",
    "\n",
    "    def make_label(label_list):\n",
    "        label_list = label_list.astype(object)\n",
    "        label_dict = {}\n",
    "        for i, label in enumerate(sorted(set(label_list), key=list(label_list).index)):\n",
    "            label_dict[i] = label\n",
    "            np.putmask(label_list, label_list == label, i)\n",
    "        label_list = label_list.astype(int)\n",
    "\n",
    "        return label_list, label_dict\n",
    "\n",
    "    train_label_list, train_label_dict = make_label(np.array(train_label_list))\n",
    "    test_label_list, test_label_dict = make_label(np.array(test_label_list))\n",
    "\n",
    "\n",
    "    x_train_tensor = torch.from_numpy(train_image_list.astype(float))\n",
    "    x_test_tensor = torch.from_numpy(test_image_list.astype(float))\n",
    "    y_train_tensor = torch.from_numpy(train_label_list).to(dtype=torch.long)\n",
    "    y_test_tensor = torch.from_numpy(test_label_list).to(dtype=torch.long)\n",
    "\n",
    "\n",
    "    train_dataset = utils.TensorDataset(x_train_tensor,y_train_tensor)\n",
    "    test_dataset = utils.TensorDataset(x_test_tensor,y_test_tensor)\n",
    "\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                               batch_size=60, \n",
    "                                               shuffle=True,\n",
    "                                              num_workers=0)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                               batch_size=60, \n",
    "                                               shuffle=False,\n",
    "                                             num_workers=0)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    num_classes = len(test_list_df[0]['Label'].unique())\n",
    "\n",
    "    class CNN(nn.Module):\n",
    "\n",
    "        def __init__(self, num_classes, size_check, conv_size):\n",
    "            super(CNN, self).__init__()\n",
    "            self.features = nn.Sequential(\n",
    "                nn.Conv2d(1, 512, kernel_size=(5, conv_size), padding=0),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                # nn.MaxPool2d(kernel_size=(1,2), stride=2),\n",
    "#                 nn.Dropout(0.2),\n",
    "                \n",
    "#                 nn.Conv2d(512, 1024, kernel_size=(3, 5), padding=0),\n",
    "#                 nn.ReLU(inplace=True),\n",
    "#                 nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            )\n",
    "            self.liniear_input_size = self.features(size_check).size()\n",
    "            self.liniear_input_size = self.liniear_input_size[1]*self.liniear_input_size[2]*self.liniear_input_size[3]\n",
    "            self.classifier = nn.Sequential(\n",
    "                nn.Linear(self.liniear_input_size, num_classes),\n",
    "    #             nn.Softmax(dim=1),\n",
    "            )\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.features(x)\n",
    "            x = x.view(x.size(0), -1)\n",
    "            x = self.classifier(x)\n",
    "            return x\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    net = CNN(num_classes, torch.FloatTensor(60, 1, image_size_height, image_size_width), conv_size).to(device)\n",
    "    \n",
    "    # モデルロード\n",
    "    net.load_state_dict(torch.load(model_path))\n",
    "    # 重み固定\n",
    "    for i, param in enumerate(net.parameters()):\n",
    "        if i <= 1:\n",
    "            param.requires_grad=False\n",
    "    # 0:Conv2dのパラメータ 1:Conv2dのバイアス 2:classifierのパラメータ 3:classifierのバイアス\n",
    "\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # optimizer = optim.SGD(net.parameters(), lr=10**-5, momentum=0.9, weight_decay=5e-4)\n",
    "    optimizer = optim.SGD(net.parameters(), lr=10**-6, momentum=0.9)\n",
    "    # optimizer = optim.Adam(net.parameters(), lr=10**-3)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    train_loss_list = []\n",
    "    train_acc_list = []\n",
    "    train_f_list = []\n",
    "    val_loss_list = []\n",
    "    val_acc_list = []\n",
    "    val_f_list = []\n",
    "    \n",
    "    best_eval_acc = 0\n",
    "    not_up_counter = 0 \n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "        train_f = 0    \n",
    "        val_loss = 0\n",
    "        val_acc = 0\n",
    "        val_f = 0\n",
    "        tmp_pred_list_by_subject = []\n",
    "        tmp_label_list_by_subject = []  \n",
    "        \n",
    "        #train\n",
    "        net.train()\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            #view()での変換をしない\n",
    "            images, labels = images.to(device, dtype=torch.float), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            train_loss += loss.item()\n",
    "            train_acc += (outputs.max(1)[1] == labels).sum().item()\n",
    "            train_f += f1_score(outputs.max(1)[1].cpu(), labels.cpu(), average='macro') * len(labels)\n",
    "            #   print(outputs.max(1)[1])\n",
    "            #   print(labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        avg_train_loss = train_loss / len(train_loader.dataset)\n",
    "        avg_train_acc = train_acc / len(train_loader.dataset)\n",
    "        avg_train_f = train_f / len(train_loader.dataset)\n",
    "\n",
    "        #val\n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "          for images, labels in test_loader:\n",
    "            #view()での変換をしない\n",
    "            images = images.to(device, dtype=torch.float)\n",
    "            labels = labels.to(device)\n",
    "            outputs = net(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            val_acc += (outputs.max(1)[1] == labels).sum().item()\n",
    "            val_f += f1_score(outputs.max(1)[1].cpu(), labels.cpu(), average='macro') * len(labels)\n",
    "\n",
    "#             if epoch == (num_epochs-1):\n",
    "            tmp_pred_list_by_subject += [test_label_dict.get(x,x) for x in outputs.max(1)[1].tolist()]\n",
    "            tmp_label_list_by_subject += [test_label_dict.get(x,x) for x in labels.tolist()]\n",
    "\n",
    "        avg_val_loss = val_loss / len(test_loader.dataset)\n",
    "        avg_val_acc = val_acc / len(test_loader.dataset)\n",
    "        avg_val_f = val_f / len(test_loader.dataset)\n",
    "\n",
    "        if (epoch % 10) == 0:\n",
    "            print ('Epoch [{}/{}], Loss: {loss:.4f}, val_loss: {val_loss:.4f}, val_acc: {val_acc:.4f}, val_f: {val_f:.4f}' \n",
    "                        .format(epoch+1, num_epochs, i+1, loss=avg_train_loss, val_loss=avg_val_loss, val_acc=avg_val_acc, val_f=avg_val_f))\n",
    "            \n",
    "        train_loss_list.append(avg_train_loss)\n",
    "        train_acc_list.append(avg_train_acc)\n",
    "        train_f_list.append(avg_train_f)\n",
    "        val_loss_list.append(avg_val_loss)\n",
    "        val_acc_list.append(avg_val_acc)\n",
    "        val_f_list.append(avg_val_f)\n",
    "        \n",
    "        if avg_val_acc > best_eval_acc:\n",
    "            best_eval_acc = avg_val_acc\n",
    "            pred_list_by_subject = copy.copy(tmp_pred_list_by_subject)\n",
    "            label_list_by_subject = copy.copy(tmp_label_list_by_subject)\n",
    "            not_up_counter = 0  \n",
    "        else:\n",
    "            not_up_counter += 1\n",
    "        # if not_up_counter == 100:\n",
    "        #     break\n",
    "\n",
    "    #     scheduler.step()\n",
    "\n",
    "\n",
    "\n",
    "    if best_eval_acc > pre_best_eval_acc:\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(range(epoch+1), train_loss_list, color='blue', linestyle='-', label='train_loss')\n",
    "        plt.plot(range(epoch+1), val_loss_list, color='green', linestyle='--', label='val_loss')\n",
    "        plt.legend()\n",
    "        plt.xlim(0, num_epochs)\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('loss')\n",
    "        plt.title('Training and validation loss')\n",
    "        plt.grid()\n",
    "        plt.savefig(DIR_OUT + \"/\" + \"trial\" + str(count+1) + \"_loss.png\")\n",
    "        plt.close()\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(range(epoch+1-100, epoch+1), train_loss_list[epoch+1-100:], color='blue', linestyle='-', label='train_loss')\n",
    "        plt.plot(range(epoch+1-100, epoch+1), val_loss_list[epoch+1-100:], color='green', linestyle='--', label='val_loss')\n",
    "        plt.legend()\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('loss')\n",
    "        plt.title('Training and validation loss (last 100 epock)')\n",
    "        plt.grid()\n",
    "        plt.savefig(DIR_OUT + \"/\" + \"trial\" + str(count+1) + \"_miniloss.png\")\n",
    "        plt.close()\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(range(epoch+1), train_f_list, color='blue', linestyle='-', label='train_f')\n",
    "        plt.plot(range(epoch+1), val_f_list, color='green', linestyle='--', label='val_f')\n",
    "        plt.legend()\n",
    "        plt.xlim(0, num_epochs)\n",
    "        plt.ylim(0, 1)\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('f1-score')\n",
    "        plt.title('Training and validation f1-score')\n",
    "        plt.grid()\n",
    "        plt.savefig(DIR_OUT + \"/\" + \"trial\" + str(count+1) + \"_f1.png\")\n",
    "        plt.close()\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(range(epoch+1), train_acc_list, color='blue', linestyle='-', label='train_acc')\n",
    "        plt.plot(range(epoch+1), val_acc_list, color='green', linestyle='--', label='val_acc')\n",
    "        plt.legend()\n",
    "        plt.xlim(0, num_epochs)\n",
    "        plt.ylim(0, 1)\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('acc')\n",
    "        plt.title('Training and validation accuracy')\n",
    "        plt.grid()\n",
    "        plt.savefig(DIR_OUT + \"/\" + \"trial\" + str(count+1) + \"_acc.png\")\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # return pred_list_by_subject, label_list_by_subject, best_eval_acc\n",
    "    return tmp_pred_list_by_subject, tmp_label_list_by_subject, avg_val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_lstm_finetuning(train_list_df, test_list_df, DIR_OUT, count, pre_best_eval_acc, num_epochs, hidden_size, batch_size, num_layers, is_bi, mabiki_interval, model_path):\n",
    "    \n",
    "    num_classes = len(test_list_df[0]['Label'].unique())\n",
    "\n",
    "#     hidden_size = 500 #lstmの出力次元\n",
    "\n",
    "    input_dim = SENSORS_NUM\n",
    "#     batch_size = 40 #バッチサイズ\n",
    "    output_size = num_classes #fcの出力次元\n",
    "\n",
    "    # 画像に直す\n",
    "    # dataframeに直してるので時間かかる\n",
    "    def sensor_to_image(list_df):\n",
    "        data_list = []\n",
    "        label_list = []\n",
    "        for i in tqdm(range(len(list_df[0]))):\n",
    "            time_series_list = []\n",
    "            label_list.append(list_df[0].iloc[i]['Label'])\n",
    "\n",
    "    #         for one_sensor_df in list_df:\n",
    "    #             time_series_list.append(list(one_sensor_df.drop(['Label', 'Trial', 'Label_Trial'], axis=1).iloc[i]))\n",
    "            # センサ順を直しながらデータ作成\n",
    "            for j in [0, 1, 2,3,4,5,6,15,14,13,12,11,10,9,8,7]:\n",
    "                one_sensor_df = list_df[j].copy()\n",
    "                time_series_list.append(list(one_sensor_df.drop(['Label', 'Trial', 'Label_Trial'], axis=1).iloc[i]))\n",
    "\n",
    "            data_list.append(np.array(time_series_list).T)       \n",
    "\n",
    "        return np.array(data_list), np.array(label_list)\n",
    "\n",
    "    train_image_list, train_label_list = sensor_to_image(train_list_df)\n",
    "    test_image_list, test_label_list = sensor_to_image(test_list_df)\n",
    "\n",
    "\n",
    "\n",
    "    def make_label(label_list):\n",
    "        label_list = label_list.astype(object)\n",
    "        label_dict = {}\n",
    "        for i, label in enumerate(sorted(set(label_list), key=list(label_list).index)):\n",
    "            label_dict[i] = label\n",
    "            np.putmask(label_list, label_list == label, i)\n",
    "        label_list = label_list.astype(int)\n",
    "\n",
    "        return label_list, label_dict\n",
    "\n",
    "    train_label_list, train_label_dict = make_label(np.array(train_label_list))\n",
    "    test_label_list, test_label_dict = make_label(np.array(test_label_list))\n",
    "\n",
    "    # 間引く\n",
    "    train_image_list = train_image_list[:,::mabiki_interval,:]\n",
    "    test_image_list = test_image_list[:,::mabiki_interval,:]\n",
    "\n",
    "    x_train_tensor = torch.from_numpy(train_image_list.astype(float))\n",
    "    x_test_tensor = torch.from_numpy(test_image_list.astype(float))\n",
    "    y_train_tensor = torch.from_numpy(train_label_list).to(dtype=torch.long)\n",
    "    y_test_tensor = torch.from_numpy(test_label_list).to(dtype=torch.long)\n",
    "\n",
    "\n",
    "    train_dataset = utils.TensorDataset(x_train_tensor,y_train_tensor)\n",
    "    test_dataset = utils.TensorDataset(x_test_tensor,y_test_tensor)\n",
    "\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                               batch_size=batch_size, \n",
    "                                               shuffle=True,\n",
    "                                              num_workers=0)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                               batch_size=batch_size, \n",
    "                                               shuffle=False,\n",
    "                                             num_workers=0)\n",
    "\n",
    "\n",
    "#     g = torch.Generator()\n",
    "#     g.manual_seed(0)\n",
    "\n",
    "# #     DataLoader(\n",
    "# #         train_dataset,\n",
    "# #         batch_size=batch_size,\n",
    "# #         num_workers=num_workers,\n",
    "# #         worker_init_fn=seed_worker,\n",
    "# #         generator=g,\n",
    "# #     )\n",
    "\n",
    "#     train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "#                                                batch_size=batch_size, \n",
    "#                                                shuffle=True,\n",
    "#                                               num_workers=0,\n",
    "#                                                 worker_init_fn=seed_worker,\n",
    "#                                                 generator=g,)\n",
    "#     test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "#                                                batch_size=batch_size, \n",
    "#                                                shuffle=False,\n",
    "#                                              num_workers=0,\n",
    "#                                                 worker_init_fn=seed_worker,\n",
    "#                                                 generator=g,)\n",
    "\n",
    "\n",
    "\n",
    "    class LstmClassifier(nn.Module):\n",
    "        def __init__(self, input_dim, batch_size, hidden_size, output_size, num_layers, is_bi):\n",
    "            super(LstmClassifier, self).__init__()\n",
    "            self.input_dim = input_dim\n",
    "            self.batch_size = batch_size\n",
    "            self.hidden_size = hidden_size\n",
    "            self.output_size = output_size\n",
    "            self.num_layers = num_layers\n",
    "            self.is_bi = is_bi\n",
    "\n",
    "            self.lstm = nn.LSTM(input_dim, hidden_size, batch_first=True, num_layers=num_layers, bidirectional=is_bi) #batch_first=Trueにしてる\n",
    "#             self.lstm = nn.GRU(input_dim, hidden_size, batch_first=True, num_layers=num_layers, bidirectional=is_bi) #batch_first=Trueにしてる\n",
    "#         self.relu = nn.ReLU(inplace=True)\n",
    "            self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        def forward(self, x):\n",
    "    #         x = self.embed(x)\n",
    "            # 初期隠れ状態とセル状態を設定\n",
    "            h0 = torch.zeros(1, self.batch_size, self.hidden_size).to(device)\n",
    "            c0 = torch.zeros(1, self.batch_size, self.hidden_size).to(device)\n",
    "            # LSTMを伝播する\n",
    "            # output_seqの出力形状：（バッチサイズ、シーケンス長、出力次元）\n",
    "    #         output_seq, (h_n, c_n) = self.lstm(x, (h0, c0)) \n",
    "            output_seq, (h_n, c_n) = self.lstm(x, None)        \n",
    "#             output_seq, h_n = self.lstm(x, None) # GRU    \n",
    "\n",
    "            # 最後のタイムステップの隠れ状態をデコード\n",
    "    #         out = self.fc(self.relu(h_n[-1]))\n",
    "            out = self.fc(h_n[-1])\n",
    "            return out\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    net = LstmClassifier(input_dim, batch_size, hidden_size, output_size, num_layers, is_bi).to(device)\n",
    "\n",
    "    # モデルロード\n",
    "    net.load_state_dict(torch.load(model_path))\n",
    "    # 重み固定\n",
    "    for i, param in enumerate(net.parameters()):\n",
    "        # 最後の２層（全結合の重みとバイアス）以外固定\n",
    "        if i <= len(net.state_dict())-3:\n",
    "            param.requires_grad=False\n",
    "    \n",
    "    \n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # optimizer = optim.SGD(net.parameters(), lr=10**-5, momentum=0.9, weight_decay=5e-4)\n",
    "#     optimizer = optim.SGD(net.parameters(), lr=10**-5, momentum=0.9)\n",
    "#     optimizer = optim.SGD(net.parameters(), lr=10**-5)\n",
    "    optimizer = optim.Adam(net.parameters(), lr=10**-5)\n",
    "    # optimizer = optim.Adam(net.parameters(), lr=100)\n",
    "    # optimizer = torch.optim.RMSprop(net.parameters(), lr=0.01, alpha=0.99, eps=1e-08, weight_decay=0, momentum=0, centered=False)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "\n",
    "\n",
    "\n",
    "#     num_epochs = 500\n",
    "\n",
    "    train_loss_list = []\n",
    "    train_acc_list = []\n",
    "    train_f_list = []\n",
    "    val_loss_list = []\n",
    "    val_acc_list = []\n",
    "    val_f_list = []\n",
    "\n",
    "    best_eval_acc = 0\n",
    "    not_up_counter = 0 \n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "        train_f = 0    \n",
    "        val_loss = 0\n",
    "        val_acc = 0\n",
    "        val_f = 0\n",
    "        tmp_pred_list_by_subject = []\n",
    "        tmp_label_list_by_subject = []  \n",
    "\n",
    "        #train\n",
    "        net.train()\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            #view()での変換をしない\n",
    "            images, labels = images.to(device, dtype=torch.float), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            train_loss += loss.item()\n",
    "            train_acc += (outputs.max(1)[1] == labels).sum().item()\n",
    "            train_f += f1_score(outputs.max(1)[1].cpu(), labels.cpu(), average='macro') * len(labels)\n",
    "            #   print(outputs.max(1)[1])\n",
    "            #   print(labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        avg_train_loss = train_loss / len(train_loader.dataset)\n",
    "        avg_train_acc = train_acc / len(train_loader.dataset)\n",
    "        avg_train_f = train_f / len(train_loader.dataset)\n",
    "\n",
    "        #val\n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "          for images, labels in test_loader:\n",
    "            #view()での変換をしない\n",
    "            images = images.to(device, dtype=torch.float)\n",
    "            labels = labels.to(device)\n",
    "            outputs = net(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            val_acc += (outputs.max(1)[1] == labels).sum().item()\n",
    "            val_f += f1_score(outputs.max(1)[1].cpu(), labels.cpu(), average='macro') * len(labels)\n",
    "\n",
    "    #             if epoch == (num_epochs-1):\n",
    "            tmp_pred_list_by_subject += [test_label_dict.get(x,x) for x in outputs.max(1)[1].tolist()]\n",
    "            tmp_label_list_by_subject += [test_label_dict.get(x,x) for x in labels.tolist()]\n",
    "\n",
    "        avg_val_loss = val_loss / len(test_loader.dataset)\n",
    "        avg_val_acc = val_acc / len(test_loader.dataset)\n",
    "        avg_val_f = val_f / len(test_loader.dataset)\n",
    "\n",
    "        if (epoch % 10) == 0:\n",
    "            print ('Epoch [{}/{}], Loss: {loss:.4f}, val_loss: {val_loss:.4f}, val_acc: {val_acc:.4f}, val_f: {val_f:.4f}' \n",
    "                        .format(epoch+1, num_epochs, i+1, loss=avg_train_loss, val_loss=avg_val_loss, val_acc=avg_val_acc, val_f=avg_val_f))\n",
    "\n",
    "        train_loss_list.append(avg_train_loss)\n",
    "        train_acc_list.append(avg_train_acc)\n",
    "        train_f_list.append(avg_train_f)\n",
    "        val_loss_list.append(avg_val_loss)\n",
    "        val_acc_list.append(avg_val_acc)\n",
    "        val_f_list.append(avg_val_f)\n",
    "\n",
    "        if avg_val_acc > best_eval_acc:\n",
    "            best_eval_acc = avg_val_acc\n",
    "            pred_list_by_subject = copy.copy(tmp_pred_list_by_subject)\n",
    "            label_list_by_subject = copy.copy(tmp_label_list_by_subject)\n",
    "            not_up_counter = 0  \n",
    "        else:\n",
    "            not_up_counter += 1\n",
    "        # if not_up_counter == 100:\n",
    "        #     break\n",
    "\n",
    "    #     scheduler.step()\n",
    "\n",
    "\n",
    "\n",
    "    if best_eval_acc > pre_best_eval_acc:\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(range(epoch+1), train_loss_list, color='blue', linestyle='-', label='train_loss')\n",
    "        plt.plot(range(epoch+1), val_loss_list, color='green', linestyle='--', label='val_loss')\n",
    "        plt.legend()\n",
    "        plt.xlim(0, num_epochs)\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('loss')\n",
    "        plt.title('Training and validation loss')\n",
    "        plt.grid()\n",
    "        plt.savefig(DIR_OUT + \"/\" + \"trial\" + str(count+1) + \"_loss.png\")\n",
    "        plt.close()\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(range(epoch+1-100, epoch+1), train_loss_list[epoch+1-100:], color='blue', linestyle='-', label='train_loss')\n",
    "        plt.plot(range(epoch+1-100, epoch+1), val_loss_list[epoch+1-100:], color='green', linestyle='--', label='val_loss')\n",
    "        plt.legend()\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('loss')\n",
    "        plt.title('Training and validation loss (last 100 epock)')\n",
    "        plt.grid()\n",
    "        plt.savefig(DIR_OUT + \"/\" + \"trial\" + str(count+1) + \"_miniloss.png\")\n",
    "        plt.close()\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(range(epoch+1), train_f_list, color='blue', linestyle='-', label='train_f')\n",
    "        plt.plot(range(epoch+1), val_f_list, color='green', linestyle='--', label='val_f')\n",
    "        plt.legend()\n",
    "        plt.xlim(0, num_epochs)\n",
    "        plt.ylim(0, 1)\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('f1-score')\n",
    "        plt.title('Training and validation f1-score')\n",
    "        plt.grid()\n",
    "        plt.savefig(DIR_OUT + \"/\" + \"trial\" + str(count+1) + \"_f1.png\")\n",
    "        plt.close()\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(range(epoch+1), train_acc_list, color='blue', linestyle='-', label='train_acc')\n",
    "        plt.plot(range(epoch+1), val_acc_list, color='green', linestyle='--', label='val_acc')\n",
    "        plt.legend()\n",
    "        plt.xlim(0, num_epochs)\n",
    "        plt.ylim(0, 1)\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('acc')\n",
    "        plt.title('Training and validation accuracy')\n",
    "        plt.grid()\n",
    "        plt.savefig(DIR_OUT + \"/\" + \"trial\" + str(count+1) + \"_acc.png\")\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # return pred_list_by_subject, label_list_by_subject, best_eval_acc\n",
    "    return tmp_pred_list_by_subject, tmp_label_list_by_subject, avg_val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 事前学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 856,
     "status": "ok",
     "timestamp": 1636368198096,
     "user": {
      "displayName": "Yuki Tabuchi",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08215908307688629308"
     },
     "user_tz": -540
    },
    "id": "9tPmvko_r4z6"
   },
   "outputs": [],
   "source": [
    "def pipeline_cnn(train_list_df, test_list_df, DIR_OUT, count, pre_best_eval_acc, conv_size, num_epochs):\n",
    "\n",
    "    over_sensors_num = 4\n",
    "    image_size_height = 16+over_sensors_num\n",
    "    image_size_width = len([col for col in test_list_df[0].columns if str(col).isdecimal()])\n",
    "\n",
    "    # 画像に直す\n",
    "    # dataframeに直してるので時間かかる\n",
    "    def sensor_to_image(list_df):\n",
    "        data_list_df = []\n",
    "        label_list = []\n",
    "        for i in tqdm(range(len(list_df[0]))):\n",
    "            temp_list_df = []\n",
    "            label_list.append(list_df[0].iloc[i]['Label'])\n",
    "\n",
    "            for df in list_df:\n",
    "                temp_list_df.append(pd.DataFrame(df.iloc[i]).T.drop(['Label', 'Trial', 'Label_Trial'], axis=1))\n",
    "\n",
    "            data_list_df.append(pd.concat(temp_list_df, sort=False))\n",
    "            \n",
    "        # センサ順を一周するよう入れ替え、over_sensors_num分上のセンサを下に延長\n",
    "        for i in range(len(list_df[0])):\n",
    "            data_list_df[i] = data_list_df[i].reset_index(drop=True).reindex(index=[0, 1, 2,3,4,5,6,15,14,13,12,11,10,9,8,7]).reset_index(drop=True)\n",
    "            data_list_df[i] = pd.concat([data_list_df[i], data_list_df[i].iloc[:over_sensors_num]]).reset_index(drop=True)\n",
    " \n",
    "        return data_list_df, label_list\n",
    "\n",
    "    train_image_list, train_label_list = sensor_to_image(train_list_df)\n",
    "    test_image_list, test_label_list = sensor_to_image(test_list_df)\n",
    "\n",
    "\n",
    "    def df_to_nd(image_list):\n",
    "        for i in range(len(image_list)):\n",
    "            image_list[i] = image_list[i].values\n",
    "\n",
    "        image_list = np.array(image_list)\n",
    "\n",
    "        return image_list\n",
    "    \n",
    "    train_image_list = df_to_nd(train_image_list)\n",
    "    train_image_list = np.reshape(train_image_list, (len(train_list_df[0]), 1, image_size_height, image_size_width), order='F')\n",
    "\n",
    "    test_image_list = df_to_nd(test_image_list)\n",
    "    test_image_list = np.reshape(test_image_list, (len(test_list_df[0]), 1, image_size_height, image_size_width), order='F')\n",
    "\n",
    "\n",
    "\n",
    "    def make_label(label_list):\n",
    "        label_list = label_list.astype(object)\n",
    "        label_dict = {}\n",
    "        for i, label in enumerate(sorted(set(label_list), key=list(label_list).index)):\n",
    "            label_dict[i] = label\n",
    "            np.putmask(label_list, label_list == label, i)\n",
    "        label_list = label_list.astype(int)\n",
    "\n",
    "        return label_list, label_dict\n",
    "\n",
    "    train_label_list, train_label_dict = make_label(np.array(train_label_list))\n",
    "    test_label_list, test_label_dict = make_label(np.array(test_label_list))\n",
    "\n",
    "\n",
    "    x_train_tensor = torch.from_numpy(train_image_list.astype(float))\n",
    "    x_test_tensor = torch.from_numpy(test_image_list.astype(float))\n",
    "    y_train_tensor = torch.from_numpy(train_label_list).to(dtype=torch.long)\n",
    "    y_test_tensor = torch.from_numpy(test_label_list).to(dtype=torch.long)\n",
    "\n",
    "\n",
    "    train_dataset = utils.TensorDataset(x_train_tensor,y_train_tensor)\n",
    "    test_dataset = utils.TensorDataset(x_test_tensor,y_test_tensor)\n",
    "\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                               batch_size=60, \n",
    "                                               shuffle=True,\n",
    "                                              num_workers=0)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                               batch_size=60, \n",
    "                                               shuffle=False,\n",
    "                                             num_workers=0)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    num_classes = len(test_list_df[0]['Label'].unique())\n",
    "\n",
    "    class CNN(nn.Module):\n",
    "\n",
    "        def __init__(self, num_classes, size_check, conv_size):\n",
    "            super(CNN, self).__init__()\n",
    "            self.features = nn.Sequential(\n",
    "                nn.Conv2d(1, 512, kernel_size=(5, conv_size), padding=0),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                # nn.MaxPool2d(kernel_size=(1,2), stride=2),\n",
    "#                 nn.Dropout(0.2),\n",
    "                \n",
    "#                 nn.Conv2d(512, 1024, kernel_size=(3, 5), padding=0),\n",
    "#                 nn.ReLU(inplace=True),\n",
    "#                 nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            )\n",
    "            self.liniear_input_size = self.features(size_check).size()\n",
    "            self.liniear_input_size = self.liniear_input_size[1]*self.liniear_input_size[2]*self.liniear_input_size[3]\n",
    "            self.classifier = nn.Sequential(\n",
    "                nn.Linear(self.liniear_input_size, num_classes),\n",
    "    #             nn.Softmax(dim=1),\n",
    "            )\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.features(x)\n",
    "            x = x.view(x.size(0), -1)\n",
    "            x = self.classifier(x)\n",
    "            return x\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    net = CNN(num_classes, torch.FloatTensor(60, 1, image_size_height, image_size_width), conv_size).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # optimizer = optim.SGD(net.parameters(), lr=10**-5, momentum=0.9, weight_decay=5e-4)\n",
    "    optimizer = optim.SGD(net.parameters(), lr=10**-6, momentum=0.9)\n",
    "    # optimizer = optim.Adam(net.parameters(), lr=10**-3)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    train_loss_list = []\n",
    "    train_acc_list = []\n",
    "    train_f_list = []\n",
    "    val_loss_list = []\n",
    "    val_acc_list = []\n",
    "    val_f_list = []\n",
    "    \n",
    "    best_eval_acc = 0\n",
    "    not_up_counter = 0 \n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "        train_f = 0    \n",
    "        val_loss = 0\n",
    "        val_acc = 0\n",
    "        val_f = 0\n",
    "        tmp_pred_list_by_subject = []\n",
    "        tmp_label_list_by_subject = []  \n",
    "        \n",
    "        #train\n",
    "        net.train()\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            #view()での変換をしない\n",
    "            images, labels = images.to(device, dtype=torch.float), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            train_loss += loss.item()\n",
    "            train_acc += (outputs.max(1)[1] == labels).sum().item()\n",
    "            train_f += f1_score(outputs.max(1)[1].cpu(), labels.cpu(), average='macro') * len(labels)\n",
    "            #   print(outputs.max(1)[1])\n",
    "            #   print(labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        avg_train_loss = train_loss / len(train_loader.dataset)\n",
    "        avg_train_acc = train_acc / len(train_loader.dataset)\n",
    "        avg_train_f = train_f / len(train_loader.dataset)\n",
    "\n",
    "        #val\n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "          for images, labels in test_loader:\n",
    "            #view()での変換をしない\n",
    "            images = images.to(device, dtype=torch.float)\n",
    "            labels = labels.to(device)\n",
    "            outputs = net(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            val_acc += (outputs.max(1)[1] == labels).sum().item()\n",
    "            val_f += f1_score(outputs.max(1)[1].cpu(), labels.cpu(), average='macro') * len(labels)\n",
    "\n",
    "#             if epoch == (num_epochs-1):\n",
    "            tmp_pred_list_by_subject += [test_label_dict.get(x,x) for x in outputs.max(1)[1].tolist()]\n",
    "            tmp_label_list_by_subject += [test_label_dict.get(x,x) for x in labels.tolist()]\n",
    "\n",
    "        avg_val_loss = val_loss / len(test_loader.dataset)\n",
    "        avg_val_acc = val_acc / len(test_loader.dataset)\n",
    "        avg_val_f = val_f / len(test_loader.dataset)\n",
    "\n",
    "        if (epoch % 10) == 0:\n",
    "            print ('Epoch [{}/{}], Loss: {loss:.4f}, val_loss: {val_loss:.4f}, val_acc: {val_acc:.4f}, val_f: {val_f:.4f}' \n",
    "                        .format(epoch+1, num_epochs, i+1, loss=avg_train_loss, val_loss=avg_val_loss, val_acc=avg_val_acc, val_f=avg_val_f))\n",
    "            \n",
    "        train_loss_list.append(avg_train_loss)\n",
    "        train_acc_list.append(avg_train_acc)\n",
    "        train_f_list.append(avg_train_f)\n",
    "        val_loss_list.append(avg_val_loss)\n",
    "        val_acc_list.append(avg_val_acc)\n",
    "        val_f_list.append(avg_val_f)\n",
    "        \n",
    "        if avg_val_acc > best_eval_acc:\n",
    "            best_eval_acc = avg_val_acc\n",
    "            pred_list_by_subject = copy.copy(tmp_pred_list_by_subject)\n",
    "            label_list_by_subject = copy.copy(tmp_label_list_by_subject)\n",
    "            not_up_counter = 0  \n",
    "        else:\n",
    "            not_up_counter += 1\n",
    "        # if not_up_counter == 100:\n",
    "        #     break\n",
    "\n",
    "    #     scheduler.step()\n",
    "\n",
    "\n",
    "\n",
    "    if best_eval_acc > pre_best_eval_acc:\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(range(epoch+1), train_loss_list, color='blue', linestyle='-', label='train_loss')\n",
    "        plt.plot(range(epoch+1), val_loss_list, color='green', linestyle='--', label='val_loss')\n",
    "        plt.legend()\n",
    "        plt.xlim(0, num_epochs)\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('loss')\n",
    "        plt.title('Training and validation loss')\n",
    "        plt.grid()\n",
    "        plt.savefig(DIR_OUT + \"/\" + \"trial\" + str(count+1) + \"_loss.png\")\n",
    "        plt.close()\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(range(epoch+1-100, epoch+1), train_loss_list[epoch+1-100:], color='blue', linestyle='-', label='train_loss')\n",
    "        plt.plot(range(epoch+1-100, epoch+1), val_loss_list[epoch+1-100:], color='green', linestyle='--', label='val_loss')\n",
    "        plt.legend()\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('loss')\n",
    "        plt.title('Training and validation loss (last 100 epock)')\n",
    "        plt.grid()\n",
    "        plt.savefig(DIR_OUT + \"/\" + \"trial\" + str(count+1) + \"_miniloss.png\")\n",
    "        plt.close()\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(range(epoch+1), train_f_list, color='blue', linestyle='-', label='train_f')\n",
    "        plt.plot(range(epoch+1), val_f_list, color='green', linestyle='--', label='val_f')\n",
    "        plt.legend()\n",
    "        plt.xlim(0, num_epochs)\n",
    "        plt.ylim(0, 1)\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('f1-score')\n",
    "        plt.title('Training and validation f1-score')\n",
    "        plt.grid()\n",
    "        plt.savefig(DIR_OUT + \"/\" + \"trial\" + str(count+1) + \"_f1.png\")\n",
    "        plt.close()\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(range(epoch+1), train_acc_list, color='blue', linestyle='-', label='train_acc')\n",
    "        plt.plot(range(epoch+1), val_acc_list, color='green', linestyle='--', label='val_acc')\n",
    "        plt.legend()\n",
    "        plt.xlim(0, num_epochs)\n",
    "        plt.ylim(0, 1)\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('acc')\n",
    "        plt.title('Training and validation accuracy')\n",
    "        plt.grid()\n",
    "        plt.savefig(DIR_OUT + \"/\" + \"trial\" + str(count+1) + \"_acc.png\")\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # return pred_list_by_subject, label_list_by_subject, best_eval_acc\n",
    "    return tmp_pred_list_by_subject, tmp_label_list_by_subject, avg_val_acc, net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_lstm(train_list_df, test_list_df, DIR_OUT, count, pre_best_eval_acc, num_epochs, hidden_size, batch_size, num_layers, is_bi, mabiki_interval):\n",
    "    \n",
    "    num_classes = len(test_list_df[0]['Label'].unique())\n",
    "\n",
    "#     hidden_size = 500 #lstmの出力次元\n",
    "\n",
    "    input_dim = SENSORS_NUM\n",
    "#     batch_size = 40 #バッチサイズ\n",
    "    output_size = num_classes #fcの出力次元\n",
    "\n",
    "    # 画像に直す\n",
    "    # dataframeに直してるので時間かかる\n",
    "    def sensor_to_image(list_df):\n",
    "        data_list = []\n",
    "        label_list = []\n",
    "        for i in tqdm(range(len(list_df[0]))):\n",
    "            time_series_list = []\n",
    "            label_list.append(list_df[0].iloc[i]['Label'])\n",
    "\n",
    "    #         for one_sensor_df in list_df:\n",
    "    #             time_series_list.append(list(one_sensor_df.drop(['Label', 'Trial', 'Label_Trial'], axis=1).iloc[i]))\n",
    "            # センサ順を直しながらデータ作成\n",
    "            for j in [0, 1, 2,3,4,5,6,15,14,13,12,11,10,9,8,7]:\n",
    "                one_sensor_df = list_df[j].copy()\n",
    "                time_series_list.append(list(one_sensor_df.drop(['Label', 'Trial', 'Label_Trial'], axis=1).iloc[i]))\n",
    "\n",
    "            data_list.append(np.array(time_series_list).T)       \n",
    "\n",
    "        return np.array(data_list), np.array(label_list)\n",
    "\n",
    "    train_image_list, train_label_list = sensor_to_image(train_list_df)\n",
    "    test_image_list, test_label_list = sensor_to_image(test_list_df)\n",
    "\n",
    "\n",
    "\n",
    "    def make_label(label_list):\n",
    "        label_list = label_list.astype(object)\n",
    "        label_dict = {}\n",
    "        for i, label in enumerate(sorted(set(label_list), key=list(label_list).index)):\n",
    "            label_dict[i] = label\n",
    "            np.putmask(label_list, label_list == label, i)\n",
    "        label_list = label_list.astype(int)\n",
    "\n",
    "        return label_list, label_dict\n",
    "\n",
    "    train_label_list, train_label_dict = make_label(np.array(train_label_list))\n",
    "    test_label_list, test_label_dict = make_label(np.array(test_label_list))\n",
    "\n",
    "    # 間引く\n",
    "    train_image_list = train_image_list[:,::mabiki_interval,:]\n",
    "    test_image_list = test_image_list[:,::mabiki_interval,:]\n",
    "\n",
    "    x_train_tensor = torch.from_numpy(train_image_list.astype(float))\n",
    "    x_test_tensor = torch.from_numpy(test_image_list.astype(float))\n",
    "    y_train_tensor = torch.from_numpy(train_label_list).to(dtype=torch.long)\n",
    "    y_test_tensor = torch.from_numpy(test_label_list).to(dtype=torch.long)\n",
    "    print(x_test_tensor.size)\n",
    "    \n",
    "    train_dataset = utils.TensorDataset(x_train_tensor,y_train_tensor)\n",
    "    test_dataset = utils.TensorDataset(x_test_tensor,y_test_tensor)\n",
    "\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                               batch_size=batch_size, \n",
    "                                               shuffle=True,\n",
    "                                              num_workers=0)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                               batch_size=batch_size, \n",
    "                                               shuffle=False,\n",
    "                                             num_workers=0)\n",
    "\n",
    "    class LstmClassifier(nn.Module):\n",
    "        def __init__(self, input_dim, batch_size, hidden_size, output_size, num_layers, is_bi):\n",
    "            super(LstmClassifier, self).__init__()\n",
    "            self.input_dim = input_dim\n",
    "            self.batch_size = batch_size\n",
    "            self.hidden_size = hidden_size\n",
    "            self.output_size = output_size\n",
    "            self.num_layers = num_layers\n",
    "            self.is_bi = is_bi\n",
    "\n",
    "            self.lstm = nn.LSTM(input_dim, hidden_size, batch_first=True, num_layers=num_layers, bidirectional=is_bi) #batch_first=Trueにしてる\n",
    "#             self.lstm = nn.GRU(input_dim, hidden_size, batch_first=True, num_layers=num_layers, bidirectional=is_bi) #batch_first=Trueにしてる\n",
    "#         self.relu = nn.ReLU(inplace=True)\n",
    "            self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        def forward(self, x):\n",
    "    #         x = self.embed(x)\n",
    "            # 初期隠れ状態とセル状態を設定\n",
    "            h0 = torch.zeros(1, self.batch_size, self.hidden_size).to(device)\n",
    "            c0 = torch.zeros(1, self.batch_size, self.hidden_size).to(device)\n",
    "            # LSTMを伝播する\n",
    "            # output_seqの出力形状：（バッチサイズ、シーケンス長、出力次元）\n",
    "    #         output_seq, (h_n, c_n) = self.lstm(x, (h0, c0)) \n",
    "            output_seq, (h_n, c_n) = self.lstm(x, None)        \n",
    "#             output_seq, h_n = self.lstm(x, None) # GRU    \n",
    "\n",
    "            # 最後のタイムステップの隠れ状態をデコード\n",
    "    #         out = self.fc(self.relu(h_n[-1]))\n",
    "            out = self.fc(h_n[-1])\n",
    "            return out\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    net = LstmClassifier(input_dim, batch_size, hidden_size, output_size, num_layers, is_bi)\n",
    "    net = net.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # optimizer = optim.SGD(net.parameters(), lr=10**-5, momentum=0.9, weight_decay=5e-4)\n",
    "#     optimizer = optim.SGD(net.parameters(), lr=10**-5, momentum=0.9)\n",
    "#     optimizer = optim.SGD(net.parameters(), lr=10**-5)\n",
    "    optimizer = optim.Adam(net.parameters(), lr=10**-5)\n",
    "    # optimizer = optim.Adam(net.parameters(), lr=100)\n",
    "    # optimizer = torch.optim.RMSprop(net.parameters(), lr=0.01, alpha=0.99, eps=1e-08, weight_decay=0, momentum=0, centered=False)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "\n",
    "\n",
    "\n",
    "#     num_epochs = 500\n",
    "\n",
    "    train_loss_list = []\n",
    "    train_acc_list = []\n",
    "    train_f_list = []\n",
    "    val_loss_list = []\n",
    "    val_acc_list = []\n",
    "    val_f_list = []\n",
    "\n",
    "    best_eval_acc = 0\n",
    "    not_up_counter = 0 \n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "        train_f = 0    \n",
    "        val_loss = 0\n",
    "        val_acc = 0\n",
    "        val_f = 0\n",
    "        tmp_pred_list_by_subject = []\n",
    "        tmp_label_list_by_subject = []  \n",
    "\n",
    "        #train\n",
    "        net.train()\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            #view()での変換をしない\n",
    "            images, labels = images.to(device, dtype=torch.float), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            train_loss += loss.item()\n",
    "            train_acc += (outputs.max(1)[1] == labels).sum().item()\n",
    "            train_f += f1_score(outputs.max(1)[1].cpu(), labels.cpu(), average='macro') * len(labels)\n",
    "            #   print(outputs.max(1)[1])\n",
    "            #   print(labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        avg_train_loss = train_loss / len(train_loader.dataset)\n",
    "        avg_train_acc = train_acc / len(train_loader.dataset)\n",
    "        avg_train_f = train_f / len(train_loader.dataset)\n",
    "\n",
    "        #val\n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "          for images, labels in test_loader:\n",
    "            #view()での変換をしない\n",
    "            images = images.to(device, dtype=torch.float)\n",
    "            labels = labels.to(device)\n",
    "            outputs = net(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            val_acc += (outputs.max(1)[1] == labels).sum().item()\n",
    "            val_f += f1_score(outputs.max(1)[1].cpu(), labels.cpu(), average='macro') * len(labels)\n",
    "\n",
    "    #             if epoch == (num_epochs-1):\n",
    "            tmp_pred_list_by_subject += [test_label_dict.get(x,x) for x in outputs.max(1)[1].tolist()]\n",
    "            tmp_label_list_by_subject += [test_label_dict.get(x,x) for x in labels.tolist()]\n",
    "\n",
    "        avg_val_loss = val_loss / len(test_loader.dataset)\n",
    "        avg_val_acc = val_acc / len(test_loader.dataset)\n",
    "        avg_val_f = val_f / len(test_loader.dataset)\n",
    "\n",
    "        if (epoch % 10) == 0:\n",
    "            print ('Epoch [{}/{}], Loss: {loss:.4f}, val_loss: {val_loss:.4f}, val_acc: {val_acc:.4f}, val_f: {val_f:.4f}' \n",
    "                        .format(epoch+1, num_epochs, i+1, loss=avg_train_loss, val_loss=avg_val_loss, val_acc=avg_val_acc, val_f=avg_val_f))\n",
    "\n",
    "        train_loss_list.append(avg_train_loss)\n",
    "        train_acc_list.append(avg_train_acc)\n",
    "        train_f_list.append(avg_train_f)\n",
    "        val_loss_list.append(avg_val_loss)\n",
    "        val_acc_list.append(avg_val_acc)\n",
    "        val_f_list.append(avg_val_f)\n",
    "\n",
    "        if avg_val_acc > best_eval_acc:\n",
    "            best_eval_acc = avg_val_acc\n",
    "            pred_list_by_subject = copy.copy(tmp_pred_list_by_subject)\n",
    "            label_list_by_subject = copy.copy(tmp_label_list_by_subject)\n",
    "            not_up_counter = 0  \n",
    "        else:\n",
    "            not_up_counter += 1\n",
    "        # if not_up_counter == 100:\n",
    "        #     break\n",
    "\n",
    "    #     scheduler.step()\n",
    "\n",
    "\n",
    "\n",
    "    if best_eval_acc > pre_best_eval_acc:\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(range(epoch+1), train_loss_list, color='blue', linestyle='-', label='train_loss')\n",
    "        plt.plot(range(epoch+1), val_loss_list, color='green', linestyle='--', label='val_loss')\n",
    "        plt.legend()\n",
    "        plt.xlim(0, num_epochs)\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('loss')\n",
    "        plt.title('Training and validation loss')\n",
    "        plt.grid()\n",
    "        plt.savefig(DIR_OUT + \"/\" + \"trial\" + str(count+1) + \"_loss.png\")\n",
    "        plt.close()\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(range(epoch+1-100, epoch+1), train_loss_list[epoch+1-100:], color='blue', linestyle='-', label='train_loss')\n",
    "        plt.plot(range(epoch+1-100, epoch+1), val_loss_list[epoch+1-100:], color='green', linestyle='--', label='val_loss')\n",
    "        plt.legend()\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('loss')\n",
    "        plt.title('Training and validation loss (last 100 epock)')\n",
    "        plt.grid()\n",
    "        plt.savefig(DIR_OUT + \"/\" + \"trial\" + str(count+1) + \"_miniloss.png\")\n",
    "        plt.close()\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(range(epoch+1), train_f_list, color='blue', linestyle='-', label='train_f')\n",
    "        plt.plot(range(epoch+1), val_f_list, color='green', linestyle='--', label='val_f')\n",
    "        plt.legend()\n",
    "        plt.xlim(0, num_epochs)\n",
    "        plt.ylim(0, 1)\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('f1-score')\n",
    "        plt.title('Training and validation f1-score')\n",
    "        plt.grid()\n",
    "        plt.savefig(DIR_OUT + \"/\" + \"trial\" + str(count+1) + \"_f1.png\")\n",
    "        plt.close()\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(range(epoch+1), train_acc_list, color='blue', linestyle='-', label='train_acc')\n",
    "        plt.plot(range(epoch+1), val_acc_list, color='green', linestyle='--', label='val_acc')\n",
    "        plt.legend()\n",
    "        plt.xlim(0, num_epochs)\n",
    "        plt.ylim(0, 1)\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('acc')\n",
    "        plt.title('Training and validation accuracy')\n",
    "        plt.grid()\n",
    "        plt.savefig(DIR_OUT + \"/\" + \"trial\" + str(count+1) + \"_acc.png\")\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # return pred_list_by_subject, label_list_by_subject, best_eval_acc\n",
    "    return tmp_pred_list_by_subject, tmp_label_list_by_subject, avg_val_acc, net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 484,
     "status": "ok",
     "timestamp": 1636368198574,
     "user": {
      "displayName": "Yuki Tabuchi",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08215908307688629308"
     },
     "user_tz": -540
    },
    "id": "6nE7L0BIr4z-"
   },
   "outputs": [],
   "source": [
    "def make_input_data(DATA_PATH, moving_average_size, metric):\n",
    "\n",
    "    All_Files = natsorted(glob.glob('{}/**/*.csv'.format(DATA_PATH),recursive=True))\n",
    "    del_no_list = [] # センサ番号昇順\n",
    "    #7,9,10\n",
    "\n",
    "\n",
    "    list_df = [0]*SENSORS_NUM\n",
    "    list_list_df = [[] for col in range(SENSORS_NUM)]\n",
    "\n",
    "    # with open(\"rand_indexs_multi_dir.pkl\", \"rb\") as f:\n",
    "    #     rand_indexs = pickle.load(f) #読み出し\n",
    "    # if len(All_Files) != (len(rand_indexs)*10):\n",
    "    #     print(rand_indexsの長さがおかしいです)\n",
    "    #     sys.exit()\n",
    "\n",
    "    # df最長長探索    \n",
    "    df_len = []\n",
    "    for file in tqdm(All_Files):\n",
    "        df = pd.read_csv(file, header=0)\n",
    "        df = df.rolling(window=moving_average_size, min_periods=1).mean().dropna(how='all')\n",
    "        df_len.append(len(df))\n",
    "        max_len = np.max(df_len)\n",
    "\n",
    "    # ファイル名順でtrial順\n",
    "    for i, file in enumerate(tqdm(All_Files)):\n",
    "        file_name = os.path.basename(file)\n",
    "    #     print(file_name)\n",
    "        df = pd.read_csv(file, header=0)\n",
    "    #             print(file_name)\n",
    "\n",
    "\n",
    "        # 移動平均\n",
    "        df = df.rolling(window=moving_average_size, min_periods=1).mean().dropna(how='all')\n",
    "    #     df.drop(['day', 'time'], axis=1, inplace=True)\n",
    "    #             df.to_csv(file.replace('.csv', '') + '_MA' + '.csv', encoding='utf-8', index=False)\n",
    "\n",
    "        # ウィンドウ作成\n",
    "        for col in range(1, SENSORS_NUM+1): # sec除くため\n",
    "\n",
    "#             pad_width = (0, max_len-len(df))\n",
    "            # 16ジェスチャのためパディングをしないよう設定\n",
    "            pad_width = (0, 0)\n",
    "\n",
    "            if metric == \"eq\":\n",
    "                list_df[col-1] = pd.DataFrame(np.pad(df.iloc[:, col], pad_width, 'edge')).T\n",
    "            elif metric == \"dtw\":\n",
    "                list_df[col-1] = pd.DataFrame(np.pad(df.iloc[:, col], pad_width, 'constant', constant_values=np.nan)).T\n",
    "            else:\n",
    "                print(metricがおかしいです)\n",
    "                sys.exit()\n",
    "\n",
    "\n",
    "        for col in range(len(list_df)):\n",
    "            # ファイル名からジェスチャ列追加\n",
    "            splited_name = os.path.basename(file).split('_')\n",
    "\n",
    "            if len(splited_name) == 2:\n",
    "                gesture = splited_name[0]\n",
    "            else:\n",
    "                print('ファイル名がおかしい')\n",
    "                sys.exit()\n",
    "            list_df[col].insert(0, 'Label', gesture)\n",
    "\n",
    "            # ファイル名からTrial数列追加\n",
    "            trial_num = int(splited_name[-1].replace('T', '').replace('.csv', ''))\n",
    "            list_df[col].insert(1, 'Trial', trial_num)\n",
    "\n",
    "    #         group_id = rand_indexs[int(i/10)][trial_num-1]\n",
    "    #         list_df[col].insert(1, 'Trial', group_id)\n",
    "\n",
    "        #     # label_trial追加\n",
    "        #     gesture_trial = gesture + '_' + str(trial_num)\n",
    "        #     df.insert(2, 'Label_Trial', gesture_trial)\n",
    "\n",
    "            # ファイル名追加\n",
    "            list_df[col].insert(2, 'Label_Trial', os.path.basename(file).replace('.csv', ''))\n",
    "\n",
    "        # df追加\n",
    "        for col in range(len(list_list_df)):\n",
    "            list_list_df[col].append(list_df[col])\n",
    "\n",
    "    for col in range(len(list_list_df)):\n",
    "        list_df[col] = pd.concat(list_list_df[col], sort=False)\n",
    "\n",
    "\n",
    "    # センサ削除\n",
    "    if len(del_no_list) > 0:\n",
    "        del_no_list.reverse()\n",
    "\n",
    "        for del_no in del_no_list:\n",
    "            del list_df[del_no-1]\n",
    "\n",
    "\n",
    "\n",
    "    # センサ番号入れる\n",
    "    if feats_num == 40:\n",
    "\n",
    "        adj1_list = list(range(1, SENSORS_NUM))+[SENSORS_NUM]\n",
    "        adj2_list = list(range(2, SENSORS_NUM+1))+[1]\n",
    "        diag1_list = list(range(1, int((SENSORS_NUM/2))+1))\n",
    "        diag2_list = list(range(int(SENSORS_NUM/2)+1, SENSORS_NUM+1))\n",
    "\n",
    "        if (len(adj1_list) != len(adj2_list)) or (len(diag1_list) != len(diag2_list)):\n",
    "            print(計算用リストの長さがおかしいです)\n",
    "            sys.exit() \n",
    "\n",
    "        column_0_num = list_df[0].columns.get_loc(0)\n",
    "        # label_df = list_df[0].iloc[:,:column_0_num] # 時間かかればこっち使う\n",
    "        for adj1, adj2 in zip(adj1_list, adj2_list):\n",
    "            label_df = list_df[adj1-1].iloc[:,:column_0_num]\n",
    "            df = pd.concat([label_df, list_df[adj1-1].iloc[:,column_0_num:] - list_df[adj2-1].iloc[:,column_0_num:]], axis=1)\n",
    "            list_df.append(df)\n",
    "\n",
    "        for diag1, diag2 in zip(diag1_list, diag2_list):\n",
    "            label_df = list_df[diag1-1].iloc[:,:column_0_num]\n",
    "            df = pd.concat([label_df, list_df[diag1-1].iloc[:,column_0_num:] - list_df[diag2-1].iloc[:,column_0_num:]], axis=1)\n",
    "            list_df.append(df)\n",
    "\n",
    "\n",
    "\n",
    "    if gesutures_num == 5:\n",
    "        # ジェスチャ絞る\n",
    "        for i, df in enumerate(list_df):\n",
    "            list_df[i] = df[df['Label'].str.contains('G1S|G3S|G5S|G7S|G10S')]\n",
    "    elif gesutures_num == 10:\n",
    "        for i, df in enumerate(list_df):\n",
    "            list_df[i] = df[df['Label'].str.contains('S')]\n",
    "    elif gesutures_num == 'houkou16':\n",
    "        for i, df in enumerate(list_df):\n",
    "            df = df[~df['Label'].str.contains('9') & ~df['Label'].str.contains('10')]\n",
    "            df = df.dropna(how='all', axis=1)\n",
    "            list_df[i] = df\n",
    "\n",
    "\n",
    "\n",
    "    # 前処理\n",
    "    if prep != '生':\n",
    "    #     for sensor_num in tqdm(range(1, SENSORS_NUM+1)):\n",
    "        for sensor_num in tqdm(range(1, len(list_df)+1)):\n",
    "            df = list_df[sensor_num-1]\n",
    "            trial_list = df['Trial'].unique()\n",
    "            scaled_feature_names = [col for col in df.columns if type(col) == int]\n",
    "\n",
    "            df_list_by_trial = []\n",
    "            for trial_num in trial_list:\n",
    "\n",
    "                one_trial_df = df.query('Trial==@trial_num')\n",
    "\n",
    "                scaled_features = one_trial_df.copy()\n",
    "                features = scaled_features[scaled_feature_names]\n",
    "\n",
    "                if prep == '標準化':\n",
    "    #                             features = features - features.mean().mean()\n",
    "                    features = (features - np.nanmean(features.values))/np.nanstd(features.values)\n",
    "\n",
    "                elif prep == '最初0':\n",
    "                    features = (features.T-features.iloc[:,0].values).T\n",
    "                elif prep == '差':\n",
    "                    first_df = features.T[::window_size-overlap_size].reset_index(drop=True)\n",
    "                    last_df = features.T[window_size-1::window_size-overlap_size].reset_index(drop=True)\n",
    "                    diff_df = (last_df - first_df).dropna(how='all')\n",
    "                    features = diff_df.T\n",
    "                else:\n",
    "                    print('prepがおかしいです')\n",
    "                    sys.exit()\n",
    "\n",
    "    #             scaled_features[scaled_feature_names] = features\n",
    "                scaled_features = pd.concat([scaled_features.drop(scaled_feature_names, axis=1), features], axis=1)\n",
    "                df_list_by_trial.append(scaled_features)\n",
    "\n",
    "            list_df[sensor_num-1] = pd.concat(df_list_by_trial, sort=False)\n",
    "\n",
    "    return list_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p24cxpkPr40A"
   },
   "source": [
    "# 2. 実行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 事前学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_subs = ['isobe_split', 'yamashita_split', 'tabuchi_split', 'Sub.5_split', \n",
    "            'hirayama_split', 'nagasima_split', 'okamotomasa_split', 'okamotomarina_split', \n",
    "            'igarashi_split', 'yosida_split', 'watanabe_split', 'okuda_split', \n",
    "            'hotta_split', 'takayama_split']\n",
    "# all_subs = ['Sub.5_split', 'hirayama_split']\n",
    "subs_n = len(all_subs)\n",
    "# INPUT_FOLDER_train_list = [[sub] for sub in ['takayama_split']*len(all_subs)]\n",
    "INPUT_FOLDER_test_list = copy.copy(all_subs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "subs_num = 3\n",
    "\n",
    "SEED = 0\n",
    "fix_seed(SEED)\n",
    "INPUT_FOLDER_train_list = []\n",
    "for sub in INPUT_FOLDER_test_list:\n",
    "    learn_subs = copy.copy(INPUT_FOLDER_test_list)\n",
    "    learn_subs.remove(sub)\n",
    "    \n",
    "    INPUT_FOLDER_train_list.append(random.sample(learn_subs, subs_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76066ead759747e3a37f279680872776",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=14.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f924b89628ee46fc81286e7f568acfe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=200.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b11b255993594e019870266c7dbbd44d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=200.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c166bf16f0446d1b3275cb7e158a7be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=200.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78d60bfb71314a29b08c25d340030e56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=200.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "959e153896b24ef2b1c19ce68affdad2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=200.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "301e1ca5657f4c2aac78d49f18e82b59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=200.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d88af49a74fc4612b9fc0e0032556857",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=200.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4e3bceff47e4331974178da0d46ab68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=200.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad8cb3cb6b184bc4af6ae38ee69b30eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=480.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccede5a966674cb08d35334415ae20eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=48.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<built-in method size of Tensor object at 0x000002168FEE0B40>\n",
      "Epoch [1/300], Loss: 0.0462, val_loss: 0.0578, val_acc: 0.0417, val_f: 0.0050\n",
      "Epoch [11/300], Loss: 0.0458, val_loss: 0.0578, val_acc: 0.0833, val_f: 0.0360\n",
      "Epoch [21/300], Loss: 0.0443, val_loss: 0.0575, val_acc: 0.0625, val_f: 0.0121\n",
      "Epoch [31/300], Loss: 0.0307, val_loss: 0.0487, val_acc: 0.2083, val_f: 0.0982\n",
      "Epoch [41/300], Loss: 0.0215, val_loss: 0.0461, val_acc: 0.2083, val_f: 0.1223\n",
      "Epoch [51/300], Loss: 0.0148, val_loss: 0.0503, val_acc: 0.1042, val_f: 0.0607\n",
      "Epoch [61/300], Loss: 0.0110, val_loss: 0.0533, val_acc: 0.0833, val_f: 0.0290\n",
      "Epoch [71/300], Loss: 0.0080, val_loss: 0.0536, val_acc: 0.1042, val_f: 0.0607\n",
      "Epoch [81/300], Loss: 0.0072, val_loss: 0.0585, val_acc: 0.0833, val_f: 0.0280\n",
      "Epoch [91/300], Loss: 0.0048, val_loss: 0.0565, val_acc: 0.0833, val_f: 0.0294\n",
      "Epoch [101/300], Loss: 0.0040, val_loss: 0.0583, val_acc: 0.0833, val_f: 0.0290\n",
      "Epoch [111/300], Loss: 0.0038, val_loss: 0.0597, val_acc: 0.0833, val_f: 0.0283\n",
      "Epoch [121/300], Loss: 0.0028, val_loss: 0.0580, val_acc: 0.0833, val_f: 0.0290\n",
      "Epoch [131/300], Loss: 0.0030, val_loss: 0.0593, val_acc: 0.0833, val_f: 0.0290\n",
      "Epoch [141/300], Loss: 0.0019, val_loss: 0.0609, val_acc: 0.0833, val_f: 0.0283\n",
      "Epoch [151/300], Loss: 0.0025, val_loss: 0.0603, val_acc: 0.0833, val_f: 0.0283\n",
      "Epoch [161/300], Loss: 0.0022, val_loss: 0.0616, val_acc: 0.0833, val_f: 0.0280\n",
      "Epoch [171/300], Loss: 0.0014, val_loss: 0.0637, val_acc: 0.0833, val_f: 0.0280\n",
      "Epoch [181/300], Loss: 0.0035, val_loss: 0.0609, val_acc: 0.1042, val_f: 0.0384\n",
      "Epoch [191/300], Loss: 0.0021, val_loss: 0.0624, val_acc: 0.0833, val_f: 0.0286\n",
      "Epoch [201/300], Loss: 0.0025, val_loss: 0.0677, val_acc: 0.0833, val_f: 0.0275\n",
      "Epoch [211/300], Loss: 0.0009, val_loss: 0.0651, val_acc: 0.0833, val_f: 0.0263\n",
      "Epoch [221/300], Loss: 0.0008, val_loss: 0.0651, val_acc: 0.0833, val_f: 0.0267\n",
      "Epoch [231/300], Loss: 0.0007, val_loss: 0.0657, val_acc: 0.0833, val_f: 0.0267\n",
      "Epoch [241/300], Loss: 0.0005, val_loss: 0.0654, val_acc: 0.0833, val_f: 0.0267\n",
      "Epoch [251/300], Loss: 0.0005, val_loss: 0.0659, val_acc: 0.0833, val_f: 0.0267\n",
      "Epoch [261/300], Loss: 0.0004, val_loss: 0.0663, val_acc: 0.0833, val_f: 0.0267\n",
      "Epoch [271/300], Loss: 0.0004, val_loss: 0.0665, val_acc: 0.0833, val_f: 0.0267\n",
      "Epoch [281/300], Loss: 0.0004, val_loss: 0.0667, val_acc: 0.0833, val_f: 0.0267\n",
      "Epoch [291/300], Loss: 0.0003, val_loss: 0.0671, val_acc: 0.0833, val_f: 0.0261\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'aaa' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'aaa' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "SEED = 0\n",
    "fix_seed(SEED)\n",
    "\n",
    "test_trial_list = [8, 9, 10]\n",
    "model_name = 'lstm'\n",
    "\n",
    "# LSTM\n",
    "num_epochs = 500\n",
    "hidden_size = 512\n",
    "batch_size = 60\n",
    "num_layers = 3\n",
    "is_bi = True\n",
    "mabiki_interval = 8\n",
    "\n",
    "# CNN\n",
    "conv_size = 60\n",
    "num_epochs = 300\n",
    "\n",
    "# kNN\n",
    "metric = \"dtw\" # \"dtw\" or \"eq\"\n",
    "\n",
    "\n",
    "prep_list = ['生', '最初0', '標準化']\n",
    "#     prep_list = ['生', '最初0', '差', '標準化']\n",
    "gesutures_num_list = ['houkou16'] # 5or10or20\n",
    "feats_num_list = [16]\n",
    "\n",
    "# option_name = ''\n",
    "option_name = '_'+str(conv_size)+'size' +'_'+str(num_epochs)+'epock'\n",
    "\n",
    "# moving_average_size_list = [1, 5, 10, 15, 20]\n",
    "moving_average_size = 10\n",
    "\n",
    "window_size = 20\n",
    "overlap_size = 19\n",
    "for prep in prep_list:\n",
    "    \n",
    "#     option_name_top = '_事前'+str(len(INPUT_FOLDER_train_list[0])) +'_'+model_name +'_'+str(conv_size)+'size' +'_'+str(num_epochs)+'epock' +'_'+prep\n",
    "\n",
    "    if model_name == 'lstm':\n",
    "        option_name_top = '_事前'+str(len(INPUT_FOLDER_train_list[0])) +'_'+model_name +'_'+str(num_epochs)+'epock' +'_'+prep\n",
    "    elif model_name == 'cnn':\n",
    "        option_name_top = '_事前'+str(len(INPUT_FOLDER_train_list[0])) +'_'+model_name +'_'+str(conv_size)+'size' +'_'+str(num_epochs)+'epock' +'_'+prep  \n",
    "    \n",
    "    # prep_list = ['生', '最初0', '差', '標準化']\n",
    "    # feats_num_list = [16, 40]\n",
    "    # INPUT_FOLDER_list = ['nagasima_split', 'Sub.5_split', 'hirayama_split', 'tabuchi_split', 'okamotomasa_split', 'yosida_split', 'okuda_split', 'okamotomarina_split']\n",
    "\n",
    "\n",
    "\n",
    "    # INPUT_FOLDER_list = ['nagasima_split', 'hirayama_split', 'tabuchi_split', 'okamotomasa_split', 'yosida_split', 'okuda_split', 'okamotomarina_split']\n",
    "\n",
    "#     INPUT_FOLDER_train_list = [['Sub.5_split', 'hirayama_split', 'tabuchi_split', \n",
    "#                          'okamotomasa_split', 'yosida_split', 'okuda_split', \n",
    "#                          'okamotomarina_split', 'nagasima_split', 'isobe_split', \n",
    "#                         'igarashi_split', 'hotta_split', 'watanabe_split', \n",
    "#                          'takayama_split', 'yamashita_split']]\n",
    "#     INPUT_FOLDER_train_list = [['Sub.5_split', 'hirayama_split', 'tabuchi_split', \n",
    "#                          'okamotomasa_split', 'yosida_split', \n",
    "#                           'nagasima_split', 'isobe_split', \n",
    "#                         'igarashi_split', 'hotta_split', 'watanabe_split', \n",
    "#                          'takayama_split']]\n",
    "#     INPUT_FOLDER_train_list = [['isobe_split', 'hirayama_split', 'nagasima_split', 'okamotomasa_split']] #2Dlist\n",
    "#     INPUT_FOLDER_train_list = [['isobe_split']] #2Dlist\n",
    "#     INPUT_FOLDER_test_list = ['yamashita_split']\n",
    "\n",
    "#     INPUT_FOLDER_train_list = [['Sub.5_split', 'hirayama_split', 'tabuchi_split', \n",
    "#                      'okamotomasa_split', 'yosida_split', 'okuda_split', \n",
    "#                      'yamashita_split', 'nagasima_split', 'yamashita_split', \n",
    "#                     'igarashi_split', 'hotta_split', 'watanabe_split', \n",
    "#                      'takayama_split']]\n",
    "#     INPUT_FOLDER_train_list = [['yamashita_split', 'hirayama_split', 'nagasima_split', 'okamotomasa_split']] #2Dlist\n",
    "#     INPUT_FOLDER_test_list = ['isobe_split']\n",
    "\n",
    "#     nSplit = 10\n",
    "    all_acc_list = []\n",
    "    for INPUT_FOLDER_train, INPUT_FOLDER_test in tqdm(zip(INPUT_FOLDER_train_list, INPUT_FOLDER_test_list), total=len(INPUT_FOLDER_test_list)):\n",
    "        for gesutures_num in gesutures_num_list:\n",
    "#             for prep in prep_list:\n",
    "            for feats_num in feats_num_list:\n",
    "\n",
    "                train_subs_name = []\n",
    "                for i, sub in enumerate(INPUT_FOLDER_train):\n",
    "                    if i == 0:\n",
    "                        DATA_PATH_train = '.' + \"./data_split/\" + sub + \"/3. STEP3/3-1 条件(照明：普通、表情：無、振動：静止)、タスク：ジェスチャ\"\n",
    "                        train_list_df = make_input_data(DATA_PATH_train, moving_average_size, metric)\n",
    "                    else:\n",
    "                        DATA_PATH_train = '.' + \"./data_split/\" + sub + \"/3. STEP3/3-1 条件(照明：普通、表情：無、振動：静止)、タスク：ジェスチャ\"\n",
    "                        train_list_df_temp = make_input_data(DATA_PATH_train, moving_average_size, metric)\n",
    "                        for j in range(len(train_list_df)):\n",
    "                            train_list_df[j] = pd.concat([train_list_df[j], train_list_df_temp[j]],0)\n",
    "                    train_subs_name.append(sub.replace('_split', ''))\n",
    "                train_subs_name = 'train-'+','.join(sorted(train_subs_name))\n",
    "\n",
    "\n",
    "                DATA_PATH_test = '.' + \"./data_split/\" + INPUT_FOLDER_test + \"/3. STEP3/3-1 条件(照明：普通、表情：無、振動：静止)、タスク：ジェスチャ\"\n",
    "                test_list_df = make_input_data(DATA_PATH_test, moving_average_size, metric)\n",
    "\n",
    "                # 使うtrial数分抽出\n",
    "                for i in range(SENSORS_NUM):\n",
    "                    test_list_df[i] = test_list_df[i][test_list_df[i]['Trial'].isin(test_trial_list)]\n",
    "\n",
    "                if model_name=='knn':\n",
    "                    DIR_OUT = './' + 'ジェスチャ通常環境'+option_name_top + '/' + INPUT_FOLDER_test.replace('_split', '') + '_makemodel' +'/'+ train_subs_name + '/１普通状態_' + str(gesutures_num) + 'G_' + str(feats_num) + 'feats_' + prep + '_' + str(moving_average_size)+'sma' + '_'+model_name+metric\n",
    "                else:\n",
    "                    DIR_OUT = './' + 'ジェスチャ通常環境'+option_name_top + '/' + INPUT_FOLDER_test.replace('_split', '') + '_makemodel' +'/'+ train_subs_name + '/１普通状態_' + str(gesutures_num) + 'G_' + str(feats_num) + 'feats_' + prep + '_' + str(moving_average_size)+'sma' + '_'+model_name\n",
    "\n",
    "                os.makedirs(DIR_OUT, exist_ok=True)\n",
    "\n",
    "\n",
    "                df = train_list_df[0]\n",
    "                class_num = len(set(df[\"Label\"]))\n",
    "\n",
    "\n",
    "                if model_name == 'knn':\n",
    "                    def DTW(a, b):\n",
    "                        return fastdtw(a, b)[0]\n",
    "\n",
    "                #     clf = Pipeline([(\"scaler\", StandardScaler()), (\"svc\", SVC())])\n",
    "                #     clf = Pipeline([(\"scaler\", StandardScaler()), (\"knn\", KNeighborsClassifier(n_neighbors=5, n_jobs=-1))])\n",
    "\n",
    "                    if metric == \"eq\":\n",
    "                        clf = KNeighborsClassifier(n_neighbors=7, n_jobs=-1)\n",
    "                #         , weights='distance'\n",
    "                    elif metric == \"dtw\":\n",
    "                        clf = KNeighborsTimeSeriesClassifier(n_neighbors=7, metric=\"dtw\", n_jobs=-1)\n",
    "                #         , weights='distance'\n",
    "                #         clf = KNeighborsClassifier(metric=DTW, n_neighbors=11, n_jobs=-1)\n",
    "                    else:\n",
    "                        print('metricがおかしいです')\n",
    "                        sys.exit()\n",
    "\n",
    "                #     param_grid = [{'knn__n_neighbors': [3]}]\n",
    "\n",
    "\n",
    "                # kf = KFold(n_splits=nSplit, shuffle=False)\n",
    "                # kf_grid = KFold(n_splits=nSplit_grid, shuffle=True)\n",
    "                # kf_grid = KFold(n_splits=nSplit-1)\n",
    "\n",
    "#                     kf = GroupKFold(n_splits=nSplit)\n",
    "#                     kf_grid = GroupKFold(n_splits=nSplit-1)\n",
    "\n",
    "\n",
    "                param_list = []\n",
    "                accuracy_list = []\n",
    "                test_df_list = []\n",
    "                # テスト\n",
    "#                     for count, (train_index, test_index) in enumerate(tqdm(kf.split(df.drop(['Label', 'Trial', 'Label_Trial'], axis=1), df['Label'], df['Trial']), total=nSplit)):                    \n",
    "                count = 0\n",
    "\n",
    "                if model_name != 'knn':\n",
    "#                         # train, test分割   \n",
    "#                         train_list_df = []\n",
    "#                         test_list_df = []\n",
    "#                         for df in list_df:\n",
    "#                             train_list_df.append(df.iloc[train_index])\n",
    "#                             test_list_df.append(df.iloc[test_index])\n",
    "\n",
    "#                       # l_p_df用、エラー出さないため\n",
    "                    test_df = test_list_df[0].copy()\n",
    "\n",
    "#                     tmp_Y_pred, tmp_Y_test, tmp_best_eval_acc = pipeline(train_list_df, test_list_df, DIR_OUT, count)\n",
    "                    pre_best_eval_acc = 0\n",
    "                    best_eval_acc_list = []\n",
    "                    for random_counter in range(1):\n",
    "                        if model_name == 'cnn':\n",
    "                            tmp_Y_pred, tmp_Y_test, tmp_best_eval_acc, net = pipeline_cnn(train_list_df, test_list_df, \n",
    "                                                                                 DIR_OUT, count, pre_best_eval_acc, \n",
    "                                                                                conv_size, num_epochs)\n",
    "                        elif model_name == 'lstm':\n",
    "                            tmp_Y_pred, tmp_Y_test, tmp_best_eval_acc, net = pipeline_lstm(train_list_df, test_list_df, \n",
    "                                                                                 DIR_OUT, count, pre_best_eval_acc, \n",
    "                                                                                num_epochs, hidden_size, batch_size, \n",
    "                                                                                num_layers, is_bi, mabiki_interval)\n",
    "                            aaa\n",
    "                        if tmp_best_eval_acc > pre_best_eval_acc:\n",
    "                            best_eval_acc = tmp_best_eval_acc\n",
    "                            Y_pred = copy.copy(tmp_Y_pred)\n",
    "                            Y_test = copy.copy(tmp_Y_test)\n",
    "                        best_eval_acc_list.append(tmp_best_eval_acc)\n",
    "                        pre_best_eval_acc = tmp_best_eval_acc\n",
    "                    print(best_eval_acc_list) \n",
    "\n",
    "                    test_df_list.append(test_df)            \n",
    "\n",
    "                    model_path = model_name+option_name+'_'+prep+'_'+train_subs_name.replace('train-', '')+'.pth'\n",
    "                    torch.save(net.state_dict(), model_path)\n",
    "\n",
    "                elif model_name == 'knn':\n",
    "                    Y_proba = np.zeros((len(test_list_df[0]), class_num))\n",
    "                    for train_df, test_df in tqdm(zip(train_list_df, test_list_df), total=len(test_list_df)):\n",
    "#                         train_df = df.iloc[train_index]\n",
    "#                         test_df = df.iloc[test_index]\n",
    "                        data_train = train_df.drop(['Label', 'Trial', 'Label_Trial'], axis=1)\n",
    "                        label_train = train_df.loc[:, 'Label']\n",
    "                        group_train = train_df.loc[:, 'Trial']\n",
    "                        data_test = test_df.drop(['Label', 'Trial', 'Label_Trial'], axis=1)\n",
    "                        label_test = test_df.loc[:, 'Label']\n",
    "\n",
    "                        if model_name == 'knn':\n",
    "                            clf.fit(data_train, label_train)\n",
    "                #             Y_pred = clf.predict(data_test)\n",
    "                            Y_proba += clf.predict_proba(data_test.values)\n",
    "\n",
    "                    Y_pred = Y_proba.argmax(axis = 1).astype(object)\n",
    "                    for class_i in range(class_num):\n",
    "                        np.putmask(Y_pred, Y_pred == class_i, clf.classes_[class_i])\n",
    "                    Y_test = label_test\n",
    "                    test_df_list.append(test_df)\n",
    "\n",
    "\n",
    "\n",
    "                warnings.filterwarnings('ignore')\n",
    "                recall = recall_score(Y_test, Y_pred, average=\"weighted\")\n",
    "                precision = precision_score(Y_test, Y_pred, average=\"weighted\")\n",
    "                fMeasure = f1_score(Y_test, Y_pred, average=\"weighted\")\n",
    "                labels = natsorted(list(set(Y_test)))\n",
    "                cmx_data = confusion_matrix(Y_test, Y_pred, labels=labels)\n",
    "                df_cmx = pd.DataFrame(cmx_data, index=labels, columns=labels)\n",
    "                report = classification_report(Y_test, Y_pred, target_names=labels, labels=labels, output_dict=True)\n",
    "                df_report = pd.DataFrame(report)\n",
    "\n",
    "                if count == 0:\n",
    "                    mean_df_report = df_report\n",
    "                    sum_df_cmx = df_cmx\n",
    "                    all_Y_pred = Y_pred\n",
    "                else:\n",
    "                    mean_df_report += df_report\n",
    "                    sum_df_cmx += df_cmx\n",
    "                    all_Y_pred = np.append(all_Y_pred, Y_pred)\n",
    "\n",
    "                os.makedirs(DIR_OUT, exist_ok=True)\n",
    "#                     df_report.to_csv(DIR_OUT + \"/\" + \"trial\" + str(count+1) + \".csv\", encoding='utf-8')\n",
    "#                     df_cmx.to_csv(DIR_OUT + \"/\" + \"trial\" + str(count+1) + \"_cmx.csv\", encoding='utf-8')\n",
    "                plt.figure(figsize=(10, 7))\n",
    "            #     sns.set(font='MS Gothic') #ラベルが日本語の場合\n",
    "                sns.heatmap(df_cmx, annot=True, cmap='Blues', fmt='g')\n",
    "                #plt.show()\n",
    "#                     plt.savefig(DIR_OUT + \"/\" + \"trial\" + str(count+1) + \"_cmx.png\", bbox_inches='tight')\n",
    "                plt.close()\n",
    "                #df_report.to_csv(DIR_OUT + \"/\" + \"trial\" + str(count+1) + \".csv\", encoding='utf-8',mode='x')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                mean_df_report /= count+1\n",
    "                mean_df_report.to_csv(DIR_OUT + \"/\" + \"trialAll.csv\", encoding='utf-8')\n",
    "\n",
    "#                     with open(DIR_OUT + '/F1score.txt', mode='w') as f:\n",
    "#                         s = str(mean_df_report.loc['f1-score', 'macro avg'])\n",
    "#                         f.write(s)\n",
    "#                     with open(\"./ジェスチャ通常環境\" + '/' + 'ジェスチャ通常環境' + 'F1score.txt', mode='a') as f:\n",
    "#                         s = DIR_OUT + '\\n'\n",
    "#                         s += str(mean_df_report.loc['f1-score', 'macro avg']) + '\\n\\n'\n",
    "#                         f.write(s)\n",
    "                with open(DIR_OUT + '/accuracy.txt', mode='w') as f:\n",
    "                    s = str(mean_df_report.at['f1-score', 'accuracy'])\n",
    "                    f.write(s)\n",
    "                all_acc_list.append(mean_df_report.loc['f1-score', 'accuracy'])\n",
    "                with open(\"./ジェスチャ通常環境\"+option_name_top + '/' + 'ジェスチャ通常環境' + 'accuracy.txt', mode='a') as f:\n",
    "                    s = DIR_OUT + '\\n'\n",
    "                    s += str(mean_df_report.at['f1-score', 'accuracy']) + '\\n\\n'\n",
    "                    f.write(s)\n",
    "\n",
    "\n",
    "#                     ss_table.at[train_subs_name.replace('train-', ''), INPUT_FOLDER_test.replace('_split', '')] = mean_df_report.at['f1-score', 'accuracy']\n",
    "\n",
    "                # result_list.append(mean_df_report['macro avg'].loc['precision'])\n",
    "                # result_list.append(mean_df_report['macro avg'].loc['recall'])\n",
    "                # result_list.append(mean_df_report['macro avg'].loc['f1-score'])\n",
    "\n",
    "                plt.figure(figsize=(10, 7))\n",
    "                sns.heatmap(sum_df_cmx, annot=True, cmap='Blues', fmt='g')\n",
    "                plt.savefig(DIR_OUT + \"/\" + \"trialAll_cmx.png\", bbox_inches='tight')\n",
    "                plt.close()\n",
    "                sum_df_cmx.to_csv(DIR_OUT + \"/\" + \"trialAll_cmx.csv\", encoding='utf-8')\n",
    "\n",
    "#                     if model_name != 'knn':\n",
    "#                         with open(DIR_OUT + '/param.txt', mode='w') as f:\n",
    "#                             for i in range(nSplit):\n",
    "#                                 s = \"trial\" +str(i+1) + '\\n' + 'param : ' + str(param_list[i]) + '\\n' + 'accuracy : ' + str(accuracy_list[i]) + '\\n\\n'\n",
    "#                                 f.write(s)\n",
    "\n",
    "                l_p_df = pd.concat(test_df_list, sort=False)\n",
    "                label = l_p_df['Label']\n",
    "                l_p_df = l_p_df.drop('Label', axis=1)\n",
    "                l_p_df.insert(2, 'Label', label)\n",
    "                l_p_df.insert(3, 'prediction_label', all_Y_pred)\n",
    "                l_p_df.to_csv(DIR_OUT + \"/\" + \"prediction.csv\", encoding='utf-8')\n",
    "\n",
    "\n",
    "\n",
    "    with open(\"./ジェスチャ通常環境\"+option_name_top + '/' + 'ジェスチャ通常環境' + 'accuracy.txt', mode='a') as f:\n",
    "        s = 'all_mean' + '\\n'\n",
    "        s += str(np.mean(all_acc_list)) + '\\n\\n'\n",
    "        f.write(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 ファインチューニング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_subs = ['isobe_split', 'yamashita_split', 'tabuchi_split', 'Sub.5_split', \n",
    "            'hirayama_split', 'nagasima_split', 'okamotomasa_split', 'okamotomarina_split', \n",
    "            'igarashi_split', 'yosida_split', 'watanabe_split', 'okuda_split', \n",
    "            'hotta_split', 'takayama_split']\n",
    "# all_subs = ['Sub.5_split', 'hirayama_split', 'isobe_split']\n",
    "subs_n = len(all_subs)\n",
    "INPUT_FOLDER_train_list = [[sub] for sub in all_subs]\n",
    "INPUT_FOLDER_test_list = copy.copy(all_subs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path_list = ['lstm_60batch_500epock_標準化4人.pth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6adad6464f347578e5ae584a4246b8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15cdd8660f9e4df1bc6932ebbca3b4b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=200.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "922d457aac0f4b039defe9e4a7eef471",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=200.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b982425ee654cc493171632546e7444",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=16.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd6c26c36928416198b57bf393127347",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=200.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fe0e538a27e4445bda77e675b57e64e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=200.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d807ef8dd50e429982280514140d6157",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=16.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f68775522eb546a9ad4923d5c529ac2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=64.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38630b68077c49c687993748a9fdf304",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=48.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [1/500], Loss: 0.0429, val_loss: 0.0302, val_acc: 0.4583, val_f: 0.3665\n",
      "Epoch [11/500], Loss: 0.0448, val_loss: 0.0237, val_acc: 0.5208, val_f: 0.4445\n",
      "Epoch [21/500], Loss: 0.0380, val_loss: 0.0202, val_acc: 0.6042, val_f: 0.5472\n",
      "Epoch [31/500], Loss: 0.0368, val_loss: 0.0183, val_acc: 0.5625, val_f: 0.5091\n",
      "Epoch [41/500], Loss: 0.0296, val_loss: 0.0163, val_acc: 0.5625, val_f: 0.5080\n",
      "Epoch [51/500], Loss: 0.0200, val_loss: 0.0156, val_acc: 0.6667, val_f: 0.6200\n",
      "Epoch [61/500], Loss: 0.0225, val_loss: 0.0153, val_acc: 0.7083, val_f: 0.6539\n",
      "Epoch [71/500], Loss: 0.0214, val_loss: 0.0142, val_acc: 0.7083, val_f: 0.6539\n",
      "Epoch [81/500], Loss: 0.0218, val_loss: 0.0135, val_acc: 0.7292, val_f: 0.6875\n",
      "Epoch [91/500], Loss: 0.0193, val_loss: 0.0138, val_acc: 0.7292, val_f: 0.6885\n",
      "Epoch [101/500], Loss: 0.0186, val_loss: 0.0128, val_acc: 0.7292, val_f: 0.6838\n",
      "Epoch [111/500], Loss: 0.0133, val_loss: 0.0127, val_acc: 0.7292, val_f: 0.6885\n",
      "Epoch [121/500], Loss: 0.0202, val_loss: 0.0123, val_acc: 0.7292, val_f: 0.6838\n",
      "Epoch [131/500], Loss: 0.0154, val_loss: 0.0124, val_acc: 0.7083, val_f: 0.6473\n",
      "Epoch [141/500], Loss: 0.0103, val_loss: 0.0122, val_acc: 0.7292, val_f: 0.6885\n",
      "Epoch [151/500], Loss: 0.0163, val_loss: 0.0119, val_acc: 0.7708, val_f: 0.7292\n",
      "Epoch [161/500], Loss: 0.0161, val_loss: 0.0115, val_acc: 0.7708, val_f: 0.7332\n",
      "Epoch [171/500], Loss: 0.0171, val_loss: 0.0118, val_acc: 0.7500, val_f: 0.7092\n",
      "Epoch [181/500], Loss: 0.0133, val_loss: 0.0115, val_acc: 0.7917, val_f: 0.7546\n",
      "Epoch [191/500], Loss: 0.0133, val_loss: 0.0112, val_acc: 0.7708, val_f: 0.7292\n",
      "Epoch [201/500], Loss: 0.0128, val_loss: 0.0116, val_acc: 0.7500, val_f: 0.7115\n",
      "Epoch [211/500], Loss: 0.0085, val_loss: 0.0116, val_acc: 0.7292, val_f: 0.6885\n",
      "Epoch [221/500], Loss: 0.0132, val_loss: 0.0113, val_acc: 0.7708, val_f: 0.7292\n",
      "Epoch [231/500], Loss: 0.0100, val_loss: 0.0112, val_acc: 0.7708, val_f: 0.7292\n",
      "Epoch [241/500], Loss: 0.0127, val_loss: 0.0108, val_acc: 0.7917, val_f: 0.7546\n",
      "Epoch [251/500], Loss: 0.0102, val_loss: 0.0103, val_acc: 0.8333, val_f: 0.8205\n",
      "Epoch [261/500], Loss: 0.0138, val_loss: 0.0100, val_acc: 0.8333, val_f: 0.8205\n",
      "Epoch [271/500], Loss: 0.0097, val_loss: 0.0101, val_acc: 0.8125, val_f: 0.7951\n",
      "Epoch [281/500], Loss: 0.0108, val_loss: 0.0100, val_acc: 0.8333, val_f: 0.8205\n",
      "Epoch [291/500], Loss: 0.0124, val_loss: 0.0101, val_acc: 0.8125, val_f: 0.7760\n",
      "Epoch [301/500], Loss: 0.0111, val_loss: 0.0104, val_acc: 0.7917, val_f: 0.7594\n",
      "Epoch [311/500], Loss: 0.0105, val_loss: 0.0100, val_acc: 0.7917, val_f: 0.7594\n",
      "Epoch [321/500], Loss: 0.0100, val_loss: 0.0098, val_acc: 0.8125, val_f: 0.7760\n",
      "Epoch [331/500], Loss: 0.0118, val_loss: 0.0096, val_acc: 0.7917, val_f: 0.7594\n",
      "Epoch [341/500], Loss: 0.0089, val_loss: 0.0095, val_acc: 0.8333, val_f: 0.8015\n",
      "Epoch [351/500], Loss: 0.0103, val_loss: 0.0094, val_acc: 0.8542, val_f: 0.8229\n",
      "Epoch [361/500], Loss: 0.0114, val_loss: 0.0093, val_acc: 0.8333, val_f: 0.8125\n",
      "Epoch [371/500], Loss: 0.0092, val_loss: 0.0093, val_acc: 0.8333, val_f: 0.8125\n",
      "Epoch [381/500], Loss: 0.0104, val_loss: 0.0092, val_acc: 0.8333, val_f: 0.8125\n",
      "Epoch [391/500], Loss: 0.0093, val_loss: 0.0093, val_acc: 0.8333, val_f: 0.8125\n",
      "Epoch [401/500], Loss: 0.0103, val_loss: 0.0092, val_acc: 0.8542, val_f: 0.8420\n",
      "Epoch [411/500], Loss: 0.0102, val_loss: 0.0092, val_acc: 0.8333, val_f: 0.8205\n",
      "Epoch [421/500], Loss: 0.0111, val_loss: 0.0093, val_acc: 0.7917, val_f: 0.7546\n",
      "Epoch [431/500], Loss: 0.0101, val_loss: 0.0089, val_acc: 0.8125, val_f: 0.7911\n",
      "Epoch [441/500], Loss: 0.0082, val_loss: 0.0089, val_acc: 0.8125, val_f: 0.7911\n",
      "Epoch [451/500], Loss: 0.0085, val_loss: 0.0088, val_acc: 0.8333, val_f: 0.8015\n",
      "Epoch [461/500], Loss: 0.0065, val_loss: 0.0088, val_acc: 0.8542, val_f: 0.8229\n",
      "Epoch [471/500], Loss: 0.0103, val_loss: 0.0087, val_acc: 0.8333, val_f: 0.8015\n",
      "Epoch [481/500], Loss: 0.0087, val_loss: 0.0086, val_acc: 0.8125, val_f: 0.7911\n",
      "Epoch [491/500], Loss: 0.0071, val_loss: 0.0085, val_acc: 0.7917, val_f: 0.7656\n",
      "[0.7916666666666666]\n",
      "\n",
      "Wall time: 47.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "SEED = 0\n",
    "fix_seed(SEED)\n",
    "\n",
    "# train_trial_list = [1, 2,3,4,5,6,7]\n",
    "train_trial_list = [1,2,3,4]\n",
    "# train_trial_list = [1]\n",
    "test_trial_list = [8, 9, 10]\n",
    "\n",
    "\n",
    "model_name = 'cnn'\n",
    "\n",
    "# LSTM\n",
    "num_epochs = 500\n",
    "hidden_size = 512\n",
    "batch_size = 20\n",
    "num_layers = 3\n",
    "is_bi = True\n",
    "mabiki_interval = 8\n",
    "\n",
    "# CNN\n",
    "conv_size = 60\n",
    "num_epochs = 500\n",
    "\n",
    "# kNN\n",
    "metric = \"dtw\" # \"dtw\" or \"eq\"\n",
    "n_neighbors = 1\n",
    "\n",
    "# moving_average_size_list = [1, 5, 10, 15, 20]\n",
    "moving_average_size_list = [10]\n",
    "\n",
    "window_size = 20\n",
    "overlap_size = 19\n",
    "for moving_average_size in tqdm(moving_average_size_list):\n",
    "\n",
    "    # prep_list = ['生', '最初0', '差', '標準化']\n",
    "    # feats_num_list = [16, 40]\n",
    "    # INPUT_FOLDER_list = ['nagasima_split', 'Sub.5_split', 'hirayama_split', 'tabuchi_split', 'okamotomasa_split', 'yosida_split', 'okuda_split', 'okamotomarina_split']\n",
    "\n",
    "    prep_list = ['標準化']\n",
    "#     prep_list = ['生', '最初0', '差', '標準化']\n",
    "    gesutures_num_list = ['houkou16'] # 5or10or20\n",
    "    feats_num_list = [16]\n",
    "\n",
    "    # INPUT_FOLDER_list = ['nagasima_split', 'hirayama_split', 'tabuchi_split', 'okamotomasa_split', 'yosida_split', 'okuda_split', 'okamotomarina_split']\n",
    "\n",
    "#     INPUT_FOLDER_train_list = [['Sub.5_split', 'hirayama_split', 'tabuchi_split', \n",
    "#                          'okamotomasa_split', 'yosida_split', 'okuda_split', \n",
    "#                          'okamotomarina_split', 'nagasima_split', 'isobe_split', \n",
    "#                         'igarashi_split', 'hotta_split', 'watanabe_split', \n",
    "#                          'takayama_split']]\n",
    "#     INPUT_FOLDER_train_list = [['isobe_split', 'hirayama_split', 'nagasima_split', 'okamotomasa_split']] #2Dlist\n",
    "#     INPUT_FOLDER_train_list = [['yamashita_split']] #2Dlist\n",
    "#     INPUT_FOLDER_test_list = ['yamashita_split']\n",
    "\n",
    "#     INPUT_FOLDER_train_list = [['Sub.5_split', 'hirayama_split', 'tabuchi_split', \n",
    "#                      'okamotomasa_split', 'yosida_split', 'okuda_split', \n",
    "#                      'yamashita_split', 'nagasima_split', 'yamashita_split', \n",
    "#                     'igarashi_split', 'hotta_split', 'watanabe_split', \n",
    "#                      'takayama_split']]\n",
    "#     INPUT_FOLDER_train_list = [['okamotomarina_split']] #2Dlist\n",
    "#     INPUT_FOLDER_test_list = ['okamotomarina_split']\n",
    "#     INPUT_FOLDER_train_list = [['okuda_split']] #2Dlist\n",
    "#     INPUT_FOLDER_test_list = ['okuda_split']   \n",
    "\n",
    "#     nSplit = 10\n",
    "    for INPUT_FOLDER_train, INPUT_FOLDER_test, model_path in tqdm(zip(INPUT_FOLDER_train_list, INPUT_FOLDER_test_list, model_path_list), total=len(INPUT_FOLDER_test_list):\n",
    "        for gesutures_num in gesutures_num_list:\n",
    "            for prep in prep_list:\n",
    "                for feats_num in feats_num_list:\n",
    "\n",
    "                    train_subs_name = []\n",
    "                    for i, sub in enumerate(INPUT_FOLDER_train):\n",
    "                        if i == 0:\n",
    "                            DATA_PATH_train = '.' + \"./data_split/\" + sub + \"/3. STEP3/3-1 条件(照明：普通、表情：無、振動：静止)、タスク：ジェスチャ\"\n",
    "                            train_list_df = make_input_data(DATA_PATH_train, moving_average_size, metric)\n",
    "                        else:\n",
    "                            DATA_PATH_train = '.' + \"./data_split/\" + sub + \"/3. STEP3/3-1 条件(照明：普通、表情：無、振動：静止)、タスク：ジェスチャ\"\n",
    "                            train_list_df_temp = make_input_data(DATA_PATH_train, moving_average_size, metric)\n",
    "                            for j in range(len(train_list_df)):\n",
    "                                train_list_df[j] = pd.concat([train_list_df[j], train_list_df_temp[j]],0)\n",
    "                        train_subs_name.append(sub.replace('_split', ''))\n",
    "                    train_subs_name = 'train-'+','.join(sorted(train_subs_name))\n",
    "                    \n",
    "\n",
    "                    DATA_PATH_test = '.' + \"./data_split/\" + INPUT_FOLDER_test + \"/3. STEP3/3-1 条件(照明：普通、表情：無、振動：静止)、タスク：ジェスチャ\"\n",
    "                    test_list_df = make_input_data(DATA_PATH_test, moving_average_size, metric)\n",
    "                    \n",
    "                    # 使うtrial数分抽出\n",
    "                    for i in range(SENSORS_NUM):\n",
    "                        train_list_df[i] = train_list_df[i][train_list_df[i]['Trial'].isin(train_trial_list)]\n",
    "                        test_list_df[i] = test_list_df[i][test_list_df[i]['Trial'].isin(test_trial_list)]\n",
    "                    \n",
    "                    if model_name=='knn':\n",
    "                        DIR_OUT = './' + 'ジェスチャ通常環境' + '/' + INPUT_FOLDER_test.replace('_split', '') +'/'+ train_subs_name + '/１普通状態_' + str(gesutures_num) + 'G_' + str(feats_num) + 'feats_' + prep + '_' + str(moving_average_size)+'sma' + '_'+model_name+metric\n",
    "                    else:\n",
    "                        DIR_OUT = './' + 'ジェスチャ通常環境' + '/' + INPUT_FOLDER_test.replace('_split', '') +'/'+ train_subs_name + '/１普通状態_' + str(gesutures_num) + 'G_' + str(feats_num) + 'feats_' + prep + '_' + str(moving_average_size)+'sma' + '_'+model_name\n",
    "\n",
    "                    os.makedirs(DIR_OUT, exist_ok=True)\n",
    "                    \n",
    "\n",
    "                    df = train_list_df[0]\n",
    "                    class_num = len(set(df[\"Label\"]))\n",
    "\n",
    "                    \n",
    "                    if model_name == 'knn':\n",
    "                        def DTW(a, b):\n",
    "                            return fastdtw(a, b)[0]\n",
    "\n",
    "                    #     clf = Pipeline([(\"scaler\", StandardScaler()), (\"svc\", SVC())])\n",
    "                    #     clf = Pipeline([(\"scaler\", StandardScaler()), (\"knn\", KNeighborsClassifier(n_neighbors=5, n_jobs=-1))])\n",
    "\n",
    "                        if metric == \"eq\":\n",
    "                            clf = KNeighborsClassifier(n_neighbors=n_neighbors, n_jobs=-1)\n",
    "                    #         , weights='distance'\n",
    "                        elif metric == \"dtw\":\n",
    "                            clf = KNeighborsTimeSeriesClassifier(n_neighbors=n_neighbors, metric=\"dtw\", n_jobs=-1)\n",
    "                    #         , weights='distance'\n",
    "                    #         clf = KNeighborsClassifier(metric=DTW, n_neighbors=11, n_jobs=-1)\n",
    "                        else:\n",
    "                            print('metricがおかしいです')\n",
    "                            sys.exit()\n",
    "\n",
    "                    #     param_grid = [{'knn__n_neighbors': [3]}]\n",
    "\n",
    "\n",
    "                    # kf = KFold(n_splits=nSplit, shuffle=False)\n",
    "                    # kf_grid = KFold(n_splits=nSplit_grid, shuffle=True)\n",
    "                    # kf_grid = KFold(n_splits=nSplit-1)\n",
    "\n",
    "#                     kf = GroupKFold(n_splits=nSplit)\n",
    "#                     kf_grid = GroupKFold(n_splits=nSplit-1)\n",
    "\n",
    "\n",
    "                    param_list = []\n",
    "                    accuracy_list = []\n",
    "                    test_df_list = []\n",
    "                    # テスト\n",
    "#                     for count, (train_index, test_index) in enumerate(tqdm(kf.split(df.drop(['Label', 'Trial', 'Label_Trial'], axis=1), df['Label'], df['Trial']), total=nSplit)):                    \n",
    "                    count = 0\n",
    "\n",
    "                    if model_name != 'knn':\n",
    "#                         # train, test分割   \n",
    "#                         train_list_df = []\n",
    "#                         test_list_df = []\n",
    "#                         for df in list_df:\n",
    "#                             train_list_df.append(df.iloc[train_index])\n",
    "#                             test_list_df.append(df.iloc[test_index])\n",
    "\n",
    "#                       # l_p_df用、エラー出さないため\n",
    "                        test_df = test_list_df[0].copy()\n",
    "\n",
    "    #                     tmp_Y_pred, tmp_Y_test, tmp_best_eval_acc = pipeline(train_list_df, test_list_df, DIR_OUT, count)\n",
    "                        pre_best_eval_acc = 0\n",
    "                        best_eval_acc_list = []\n",
    "                        for random_counter in range(1):\n",
    "                            if model_name == 'cnn':\n",
    "                                tmp_Y_pred, tmp_Y_test, tmp_best_eval_acc = pipeline_cnn_finetuning(train_list_df, test_list_df, \n",
    "                                                                                     DIR_OUT, count, pre_best_eval_acc, \n",
    "                                                                                    conv_size, model_path, num_epochs)\n",
    "                            elif model_name == 'lstm':\n",
    "                                tmp_Y_pred, tmp_Y_test, tmp_best_eval_acc = pipeline_lstm_finetuning(train_list_df, test_list_df, \n",
    "                                                                                     DIR_OUT, count, pre_best_eval_acc, \n",
    "                                                                                    num_epochs, hidden_size, batch_size, \n",
    "                                                                                    num_layers, is_bi, mabiki_interval, model_path)\n",
    "                            if tmp_best_eval_acc > pre_best_eval_acc:\n",
    "                                best_eval_acc = tmp_best_eval_acc\n",
    "                                Y_pred = copy.copy(tmp_Y_pred)\n",
    "                                Y_test = copy.copy(tmp_Y_test)\n",
    "                            best_eval_acc_list.append(tmp_best_eval_acc)\n",
    "                            pre_best_eval_acc = tmp_best_eval_acc\n",
    "                        print(best_eval_acc_list) \n",
    "                        \n",
    "                        test_df_list.append(test_df)            \n",
    "\n",
    "                    elif model_name == 'knn':\n",
    "                        Y_proba = np.zeros((len(test_list_df[0]), class_num))\n",
    "                        for train_df, test_df in tqdm(zip(train_list_df, test_list_df), total=len(test_list_df)):\n",
    "    #                         train_df = df.iloc[train_index]\n",
    "    #                         test_df = df.iloc[test_index]\n",
    "                            data_train = train_df.drop(['Label', 'Trial', 'Label_Trial'], axis=1)\n",
    "                            label_train = train_df.loc[:, 'Label']\n",
    "                            group_train = train_df.loc[:, 'Trial']\n",
    "                            data_test = test_df.drop(['Label', 'Trial', 'Label_Trial'], axis=1)\n",
    "                            label_test = test_df.loc[:, 'Label']\n",
    "\n",
    "                            if model_name == 'knn':\n",
    "                                clf.fit(data_train, label_train)\n",
    "                    #             Y_pred = clf.predict(data_test)\n",
    "                                Y_proba += clf.predict_proba(data_test.values)\n",
    "\n",
    "                        Y_pred = Y_proba.argmax(axis = 1).astype(object)\n",
    "                        for class_i in range(class_num):\n",
    "                            np.putmask(Y_pred, Y_pred == class_i, clf.classes_[class_i])\n",
    "                        Y_test = label_test\n",
    "                        test_df_list.append(test_df)\n",
    "                    \n",
    "                    \n",
    "\n",
    "                    warnings.filterwarnings('ignore')\n",
    "                    recall = recall_score(Y_test, Y_pred, average=\"weighted\")\n",
    "                    precision = precision_score(Y_test, Y_pred, average=\"weighted\")\n",
    "                    fMeasure = f1_score(Y_test, Y_pred, average=\"weighted\")\n",
    "                    labels = natsorted(list(set(Y_test)))\n",
    "                    cmx_data = confusion_matrix(Y_test, Y_pred, labels=labels)\n",
    "                    df_cmx = pd.DataFrame(cmx_data, index=labels, columns=labels)\n",
    "                    report = classification_report(Y_test, Y_pred, target_names=labels, labels=labels, output_dict=True)\n",
    "                    df_report = pd.DataFrame(report)\n",
    "\n",
    "                    if count == 0:\n",
    "                        mean_df_report = df_report\n",
    "                        sum_df_cmx = df_cmx\n",
    "                        all_Y_pred = Y_pred\n",
    "                    else:\n",
    "                        mean_df_report += df_report\n",
    "                        sum_df_cmx += df_cmx\n",
    "                        all_Y_pred = np.append(all_Y_pred, Y_pred)\n",
    "\n",
    "                    os.makedirs(DIR_OUT, exist_ok=True)\n",
    "#                     df_report.to_csv(DIR_OUT + \"/\" + \"trial\" + str(count+1) + \".csv\", encoding='utf-8')\n",
    "#                     df_cmx.to_csv(DIR_OUT + \"/\" + \"trial\" + str(count+1) + \"_cmx.csv\", encoding='utf-8')\n",
    "                    plt.figure(figsize=(10, 7))\n",
    "                #     sns.set(font='MS Gothic') #ラベルが日本語の場合\n",
    "                    sns.heatmap(df_cmx, annot=True, cmap='Blues', fmt='g')\n",
    "                    #plt.show()\n",
    "#                     plt.savefig(DIR_OUT + \"/\" + \"trial\" + str(count+1) + \"_cmx.png\", bbox_inches='tight')\n",
    "                    plt.close()\n",
    "                    #df_report.to_csv(DIR_OUT + \"/\" + \"trial\" + str(count+1) + \".csv\", encoding='utf-8',mode='x'                       \n",
    "                        \n",
    "                    mean_df_report /= count+1\n",
    "                    mean_df_report.to_csv(DIR_OUT + \"/\" + \"trialAll.csv\", encoding='utf-8')\n",
    "\n",
    "#                     with open(DIR_OUT + '/F1score.txt', mode='w') as f:\n",
    "#                         s = str(mean_df_report.loc['f1-score', 'macro avg'])\n",
    "#                         f.write(s)\n",
    "#                     with open(\"./ジェスチャ通常環境\" + '/' + 'ジェスチャ通常環境' + 'F1score.txt', mode='a') as f:\n",
    "#                         s = DIR_OUT + '\\n'\n",
    "#                         s += str(mean_df_report.loc['f1-score', 'macro avg']) + '\\n\\n'\n",
    "#                         f.write(s)\n",
    "                    with open(DIR_OUT + '/accuracy.txt', mode='w') as f:\n",
    "                        s = str(mean_df_report.loc['f1-score', 'accuracy'])\n",
    "                        f.write(s)\n",
    "                    with open(\"./ジェスチャ通常環境\" + '/' + 'ジェスチャ通常環境' + 'accuracy.txt', mode='a') as f:\n",
    "                        s = DIR_OUT + '\\n'\n",
    "                        s += str(mean_df_report.loc['f1-score', 'accuracy']) + '\\n\\n'\n",
    "                        f.write(s)\n",
    "                        \n",
    "                    # result_list.append(mean_df_report['macro avg'].loc['precision'])\n",
    "                    # result_list.append(mean_df_report['macro avg'].loc['recall'])\n",
    "                    # result_list.append(mean_df_report['macro avg'].loc['f1-score'])\n",
    "\n",
    "                    plt.figure(figsize=(10, 7))\n",
    "                    sns.heatmap(sum_df_cmx, annot=True, cmap='Blues', fmt='g')\n",
    "                    plt.savefig(DIR_OUT + \"/\" + \"trialAll_cmx.png\", bbox_inches='tight')\n",
    "                    plt.close()\n",
    "                    sum_df_cmx.to_csv(DIR_OUT + \"/\" + \"trialAll_cmx.csv\", encoding='utf-8')\n",
    "\n",
    "#                     if model_name != 'knn':\n",
    "#                         with open(DIR_OUT + '/param.txt', mode='w') as f:\n",
    "#                             for i in range(nSplit):\n",
    "#                                 s = \"trial\" +str(i+1) + '\\n' + 'param : ' + str(param_list[i]) + '\\n' + 'accuracy : ' + str(accuracy_list[i]) + '\\n\\n'\n",
    "#                                 f.write(s)\n",
    "\n",
    "                    l_p_df = pd.concat(test_df_list, sort=False)\n",
    "                    label = l_p_df['Label']\n",
    "                    l_p_df = l_p_df.drop('Label', axis=1)\n",
    "                    l_p_df.insert(2, 'Label', label)\n",
    "                    l_p_df.insert(3, 'prediction_label', all_Y_pred)\n",
    "                    l_p_df.to_csv(DIR_OUT + \"/\" + \"prediction.csv\", encoding='utf-8')\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "2021-11-09GradCam.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "595.2px",
    "left": "254px",
    "top": "111.125px",
    "width": "193.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "035db6d07ee0447c9451fa403766d77a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0a1dcce33b29441c855e4f8bfc55031d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0fb5375d1d2246edac16ae97bb0b71f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_674b22cda5d0420db095a27afb85068d",
      "max": 200,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1ead800eaa2845bc882e17edec2782ab",
      "value": 200
     }
    },
    "11f166b7d47947628dc514e6c95be766": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "14ed64fcd9fb42f4919844cec0191017": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2bf88adb97b44b54afa9b7921d942127",
       "IPY_MODEL_2c98381b7fe5460a82723e42e3acdbf6",
       "IPY_MODEL_c30c102504be4e8b9dda6da527a3814f"
      ],
      "layout": "IPY_MODEL_3946ae90abc04959b78ae8bee53e8569"
     }
    },
    "1b22f40e204642d486f13272098bcd65": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1dd4d51fae5543e5beae1f8568552525": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_30cbb55fcad34f66ac9771633a05d11f",
      "placeholder": "​",
      "style": "IPY_MODEL_22ca49ba9307423183a86ba1f0e99964",
      "value": " 200/200 [01:38&lt;00:00,  2.18it/s]"
     }
    },
    "1ead800eaa2845bc882e17edec2782ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "218c2f10e69949fb8d08c65b452d9bf8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "22ca49ba9307423183a86ba1f0e99964": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2797cce3423240df92d26bce8040db25": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "299191ff8ed84bb781936319e9ce341a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2bf88adb97b44b54afa9b7921d942127": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dda613958d1b45e6a7295e8db3a2f534",
      "placeholder": "​",
      "style": "IPY_MODEL_c2a74435aeb44ea68bfad6cbf8c17f70",
      "value": "100%"
     }
    },
    "2c98381b7fe5460a82723e42e3acdbf6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2797cce3423240df92d26bce8040db25",
      "max": 144,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_82c0b13ac7c740f1a91c4547ed5da503",
      "value": 144
     }
    },
    "2d4666b5ed6147ada12ca0204fd51d1f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "30cbb55fcad34f66ac9771633a05d11f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "32ade17d97ae4b18b2923901b92ec8e0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "381c6a70a8a145f1a69aa6ce2e03e370": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3946ae90abc04959b78ae8bee53e8569": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "445de55a0f7f428ab71f2482e2907e68": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "517025ee8ef2401fa68e76abc6c35be6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_11f166b7d47947628dc514e6c95be766",
      "placeholder": "​",
      "style": "IPY_MODEL_869480a83d1c47c4a8cb12e92a1e3c6f",
      "value": "100%"
     }
    },
    "53972013e0334735a79127d5c27c0edd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1b22f40e204642d486f13272098bcd65",
      "max": 200,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_936c249724684cd39be305a40922ac60",
      "value": 200
     }
    },
    "674b22cda5d0420db095a27afb85068d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6e3e03641fd945d5b29fa61b1dbfb7aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7ad675f96af544e5b9203d1d37e10f4f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7b7b456106844e00abe712e4a9e02f35": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7e8a595312ad431ebf7d48bd3d071ce2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fe15b704b55c44a5913664fddc3947dd",
       "IPY_MODEL_96866f785c5d40fbb0bd7e347181d838",
       "IPY_MODEL_b5055ffeb3d94087b6f7f77f579d041e"
      ],
      "layout": "IPY_MODEL_381c6a70a8a145f1a69aa6ce2e03e370"
     }
    },
    "7fdbe44723394eb8af1e45bc819c9218": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "82c0b13ac7c740f1a91c4547ed5da503": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "856630fce34c4adc8ddac10ce0ae07fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f060acd7852943fd983ff07ae0aa0ffc",
      "max": 16,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7b7b456106844e00abe712e4a9e02f35",
      "value": 16
     }
    },
    "869480a83d1c47c4a8cb12e92a1e3c6f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "885110469ced49ca8519d8a2f53d2855": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_32ade17d97ae4b18b2923901b92ec8e0",
      "placeholder": "​",
      "style": "IPY_MODEL_6e3e03641fd945d5b29fa61b1dbfb7aa",
      "value": "100%"
     }
    },
    "8b747a1010c743a8b007f322eed304a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2d4666b5ed6147ada12ca0204fd51d1f",
      "placeholder": "​",
      "style": "IPY_MODEL_9b6b4e05985f42fd8c7308ed05ae935a",
      "value": "100%"
     }
    },
    "936c249724684cd39be305a40922ac60": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "96866f785c5d40fbb0bd7e347181d838": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_035db6d07ee0447c9451fa403766d77a",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c8489a99c46a4ded9936c64dca3348c2",
      "value": 1
     }
    },
    "98333abe25c244b687526d370528fd29": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9b6b4e05985f42fd8c7308ed05ae935a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ac140b7e39fe4c31b0694f3cc3aac123": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "af400db7f65d4a8a875b74a06e7dc8ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b5055ffeb3d94087b6f7f77f579d041e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_98333abe25c244b687526d370528fd29",
      "placeholder": "​",
      "style": "IPY_MODEL_af400db7f65d4a8a875b74a06e7dc8ff",
      "value": " 1/1 [04:03&lt;00:00, 243.63s/it]"
     }
    },
    "b8a3529ea38b4e05aac1f1115025a1bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bf799053e404424a8ef3237825659d4b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c2a74435aeb44ea68bfad6cbf8c17f70": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c30c102504be4e8b9dda6da527a3814f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dfc8cb963f68455884329f7a34dea0eb",
      "placeholder": "​",
      "style": "IPY_MODEL_e75501b632414a73910338fbc5e3aa1e",
      "value": " 144/144 [00:26&lt;00:00,  5.60it/s]"
     }
    },
    "c8489a99c46a4ded9936c64dca3348c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cd6d72d8645a472a89285779ecfea4d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bf799053e404424a8ef3237825659d4b",
      "placeholder": "​",
      "style": "IPY_MODEL_218c2f10e69949fb8d08c65b452d9bf8",
      "value": " 16/16 [00:03&lt;00:00,  5.31it/s]"
     }
    },
    "db0892828fcb41ad89b17c13b7ec692d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8b747a1010c743a8b007f322eed304a2",
       "IPY_MODEL_53972013e0334735a79127d5c27c0edd",
       "IPY_MODEL_1dd4d51fae5543e5beae1f8568552525"
      ],
      "layout": "IPY_MODEL_445de55a0f7f428ab71f2482e2907e68"
     }
    },
    "dda613958d1b45e6a7295e8db3a2f534": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dfc8cb963f68455884329f7a34dea0eb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e1219918bce04d6b82a1d0353f4d7524": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_517025ee8ef2401fa68e76abc6c35be6",
       "IPY_MODEL_0fb5375d1d2246edac16ae97bb0b71f4",
       "IPY_MODEL_f0e8a5677031416e9ba8196f2fa18d02"
      ],
      "layout": "IPY_MODEL_299191ff8ed84bb781936319e9ce341a"
     }
    },
    "e75501b632414a73910338fbc5e3aa1e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f060acd7852943fd983ff07ae0aa0ffc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f0e8a5677031416e9ba8196f2fa18d02": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0a1dcce33b29441c855e4f8bfc55031d",
      "placeholder": "​",
      "style": "IPY_MODEL_b8a3529ea38b4e05aac1f1115025a1bd",
      "value": " 200/200 [00:09&lt;00:00, 20.69it/s]"
     }
    },
    "fe15b704b55c44a5913664fddc3947dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ac140b7e39fe4c31b0694f3cc3aac123",
      "placeholder": "​",
      "style": "IPY_MODEL_7ad675f96af544e5b9203d1d37e10f4f",
      "value": "100%"
     }
    },
    "fe8982f8e1354cb589a900bcbce28454": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_885110469ced49ca8519d8a2f53d2855",
       "IPY_MODEL_856630fce34c4adc8ddac10ce0ae07fa",
       "IPY_MODEL_cd6d72d8645a472a89285779ecfea4d8"
      ],
      "layout": "IPY_MODEL_7fdbe44723394eb8af1e45bc819c9218"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
